# QA Practice - AI Testing Fundamentals

Most useful courses to develop the skills needed in this new era of QAs in AI.

## QA_Practice-AI_Testing_Fundamentals

<https://perficient.udemy.com/learning-paths/10210909/>

[![Curso reciente ](images/2025-07-02_172635.png "Crea y Despliega un Sistema de Ventas FULL STACK con REACT y PostgreSQL | 2025")](https://www.udemy.com/course/generative-ai-for-beginners-b/)

## Section 1: Introduction to the Course

>[!NOTE]  
>Aprenderemos todo sobre IA Generativa empezando por los conceptos más fundamentales incluyendo Inteligencia
>Artificial, Machine Learning, Deep Learning para luego adentrarnos en los avanzados.
>También haremos una demostración de `ChatGPT` y aprenderemos sus características, y lo que realmente lo diferencia de todo lo
>que vino en el pasado o lo que está por venir.
>Ahora, en el módulo dos, echaremos un vistazo a algunas de las terminologías clave
>que se oyen mucho en la IA Generativa, y quiero asegurarme de que las entiendes.
>Hablaremos de LLM, Prompt Engineering, Embeddings, Fine tuning, todo esto.
>
> A continuación hablaremos de cómo la IA Generativa puede resolver algunos de los casos de uso en algunas industrias.
>Y esto le dará ideas prácticas y consejos sobre cómo utilizar la IA Generativa en su organización o trabajo,
>y crear algo a partir de ella.
>A continuación, en el módulo cuatro, crearemos un chatbot avanzado que podrá utilizar para consultar sus datos
>y formular preguntas, todo ello mediante la API `ChatGPT`.
>Y este módulo en particular va a ser increíble porque verás cómo podemos lograr
>todo eso en sólo 30 a 50 líneas de código.
>Y ese es el verdadero poder de las herramientas generativas como `ChatGPT`.

.

>[!IMPORTANT]  
>**Quick points about this learning journey**
>Hi Friends, as we progress on this learning journey, I wanted to mention three points.
>
>1 - Just to reiterate, this course entitles you to life time query support facility. So if you have any question (today, tomorrow...., or even after completing the course), do not hesitate to use the Q&A option, or email me on <aakriti.elearning@gmail.com> ... I reply to all questions within 48 hours.
>
>2 - At some point in the course, Udemy will ask you to provide a review.
>
>If you want to do it later, just click on "Ask me later" or "Ask me at the end of the course".
>
>Else you can select a star rating of your choice, and leave a small message.
>
>Your rating and feedback are very important to us. So please spare a few moments to leave a rating and feedback comments. This will hardly take 2 minutes of your time but it will help support us in creating great content like this.

## Section 2: Understanding Generative AI

### 3. Generative AI - Introduction

>[!NOTE]  
>Deep Learning, porque esto
>nos ayudará a entender todos los detalles.
>A continuación, a partir de estos aprendizajes,
>haremos una recapitulación y comprenderemos aún más la IA Generativa.
>Y por último hablaremos de `ChatGPT`, lo veremos en acción y veremos por qué de repente hay tanto revuelo
>sobre la IA Generativa.
>
>Por qué es el único tema del que se oye hablar en cada reunión, en cada post de LinkedIn, en cada artículo de Internet.
>Así que adelante.
>Empecemos.
>Así que chicos, qué es la IA Generativa como su propio nombre indica, es una combinación de Generativa e Inteligencia
>Artificial o IA.
>
>La clave aquí es que la IA utiliza esta tecnología para "generar" algo para ti, para producir algo
>nuevo.
>Chicos, este ha sido un breve resumen de tres minutos sobre la IA Generativa y por ahora lo he mantenido muy simple.
>A medida que avancemos en el curso, ampliaremos todo esto.
>
>Te voy a contar todos los aspectos de la IA Generativa de una forma muy sencilla, pero realmente, para entender las
>cosas con más profundidad, primero tenemos que entender ¿qué es la IA o Inteligencia Artificial?
>
>**¿Cómo funciona el aprendizaje automático?**
>
>Porque son como un precursor del aprendizaje de la IA Generativa.
>Así que lo que haremos es pasar al siguiente vídeo y aprender sobre IA, Aprendizaje Automático, Aprendizaje Profundo.
>Y una vez hecho esto, tendremos algunos fundamentos más resueltos,
>volveremos de nuevo a la IA Generativa y la comprenderemos aún más a fondo.

### 4. Artificial Intelligence (AI), Machine Learning (ML) & Deep Learning

>[!NOTE]  
>Así que en este vídeo vamos a hablar de Inteligencia Artificial, Machine Learning y Deep Learning.
>Y es importante entender estos temas primero porque son los antecedentes clave para conocer la
>IA Generativa.
>Así que vamos a entenderlos uno por uno.
>
>**En primer lugar, entendamos qué es la Inteligencia Artificial.**
>
>Así que los humanos son la especie más inteligente que ha existido en la Tierra.
>Destacamos en todo lo que hacemos, ya sean ciencias, artes o deportes.
>El cerebro humano es lo más inteligente de la Tierra.
>Esto sí que es inteligencia.
>Cuando intentamos replicar esta inteligencia en una máquina, es decir, cuando intentamos hacer
>una máquina tan lista, tan inteligente como un ser humano, eso se llama Inteligencia Artificial o IA.
>La Inteligencia Artificial es el desarrollo de máquinas capaces de realizar tareas que normalmente requieren inteligencia
>humana.
>
>**¿Cómo hacer que las máquinas aprendan?**
>
>Así que piénsalo.
>Y chicos, voy a ir paso a paso.
>Iremos nivel por nivel.
>Y te contaré todo esto de forma muy sencilla, muy interactiva, para que tus conceptos queden
>absolutamente claros.
>
>**Si lo piensas bien, ¿cómo aprendemos algo los humanos?**
>
>Por ejemplo, hay un niño y ¿cómo aprendería, digamos, qué es una manzana?
>Verán muchas frutas a su alrededor.
>Verán plátano, verán naranja, verán manzana.
>Y con el tiempo entenderán que, vale, todo lo que es redondo, todo lo que es de color rojo, es
>una manzana.
>Y la próxima vez que este niño vea diez frutas colocadas delante de él, podrá identificar fácilmente cuál
>es una manzana.
>Porque han memorizado algunas propiedades de la fruta, la han visto, la han aprendido, y así
>es como todos aprendemos las cosas.
>
>**¿Qué es el aprendizaje profundo?**
>
>Veamos ahora la definición.
>Es un subconjunto del Aprendizaje Automático,
>y procesa datos a través de redes neuronales.
>Y esto se traduce en una mayor precisión para los problemas complicados.
>Así que no es necesario recordar todo esto.
>Recuerda los detalles sencillos.
>
>Y sólo tres cosas es realmente lo que debes sacar de esta diapositiva.
>
>* En primer lugar, el aprendizaje profundo
>es un subconjunto del aprendizaje automático.
>
>* Dos, utiliza una red neuronal.
>
>* Y en tercer lugar, ofrece resultados mucho mejores y más precisos en caso de problemas complejos.
>
>Así que chicos, esto iba de Inteligencia Artificial, Machine Learning y Deep Learning.
>Sólo para ponerlos en una sola vista, en un solo contexto.
>Tenemos la Inteligencia Artificial, que se refiere a crear máquinas que sean inteligentes como los humanos, es decir,
>crear máquinas en las que se desea que tengan normalmente el mismo nivel de inteligencia que tienen
>originalmente los humanos.
>
>En segundo lugar, tenemos el aprendizaje automático, que podemos decir que es un facilitador de la inteligencia artificial.
>Permite a las máquinas aprender y mejorar con el tiempo.
>
>Y, por último, tenemos el aprendizaje profundo, que es un subconjunto del aprendizaje automático.
>Y utiliza redes neuronales para resolver el complejo problema.

### 5. Generative AI - Recap

>[!NOTE]
>
>![Deep Leraning, Machine Learning and Artificial Intelligence](images/2025-07-04_151459.png "Deep Leraning, Machine Learning and Artificial Intelligence")
>
>**¿Dónde encaja la IA Generativa en todo esto?**
>
>Como habrás adivinado, la IA generativa es un subconjunto del aprendizaje profundo.
>Utiliza las redes neuronales de aprendizaje profundo que vimos en el vídeo anterior para comprender los datos de entrenamiento,
>aprender de ellos y generar nuevos contenidos.
>
>Así que, de nuevo, la diferenciación clave que sigue apareciendo es esta palabra "generativa" o la capacidad
>de generar algo nuevo.
>
>![Generative AI](images/2025-07-04_152116.png "Generative AI")
>
>Los sistemas de IA existentes que denominamos sistemas de IA convencionales funcionaban de este modo.
>Les dabas datos de entrenamiento, el modelo aprendía de ellos y luego hacía predicciones o clasificaba
>los datos en categorías, o procesaba el lenguaje como traducciones, o hacía visión por ordenador como qué
>es una imagen.
>
>![Conventional AI Systems](images/2025-07-04_152513.png "Conventional AI Systems")
>
>**En cambio, la IA generativa es totalmente distinta.**
>
>Le damos al modelo de IA muchos datos de entrenamiento... mucho, mucho más de lo que normalmente hemos dado al sistema
>de IA convencional.
>Y a partir de estos datos de entrenamiento, basados en la red neuronal que opera entre bastidores, es
>capaz de generar nuevos contenidos, ya sean textos, imágenes, vídeos o lo que sea.
>
>Así que si hablamos del mismo ejemplo que hemos comentado antes, entrenamos nuestro modelo -esta vez un modelo generativo
>de IA- en el mismo conjunto de datos de imágenes de manzanas.
>Y luego le pedimos que nos genere la imagen de una manzana.
>Y puede hacerlo.
>Puede darnos esta nueva imagen.
>
>Nótese que esta imagen no procede de los millones de imágenes con las que se ha entrenado este modelo.
>No es un ejercicio extractivo.
>Es un ejercicio generativo.
>
>![Generative AI](images/2025-07-04_153118.png "Generative AI")
>
>**Y una vez más, eso es la IA Generativa.**
>
>Está generando nuevos contenidos, ya sean textos, imágenes, audio o vídeo, utilizando la Inteligencia Artificial.
>Espero que ahora lo tengas muy claro.
>Ahora que entramos en el siguiente vídeo y empezamos a hablar más en profundidad sobre la IA Generativa, cómo funciona
>entre bastidores, su aplicabilidad, todas esas cosas,
>realmente quiero que recuerdes tres cosas clave de estos vídeos anteriores.
>En primer lugar, para que las máquinas sean inteligentes y precisas, hay que entrenarlas con un gran volumen de datos.
>
>**El segundo aspecto clave es que necesitamos una gran capacidad de cálculo, y ya hemos hablado de ello.**
>
>Alimentamos un gran volumen de datos de entrenamiento,
>utilizamos redes neuronales, que
>son muy complejas.
>Esperamos respuestas rápidas cuando escribimos algo en `ChatGPT`.
>Así que la potencia de cálculo tiene que ser enorme.
>Tiene que ser muy potente para poder procesar estos datos en muy poco tiempo.
>Y en tercer lugar, estamos asistiendo a un cambio en la forma de interactuar con estos modelos de aprendizaje automático.

### 6. Explore `ChatGPT`: Features & Capabilities

>[!NOTE]
>
>![`ChatGPT` is a...](images/2025-07-04_153738.png "`ChatGPT` is a...")
>
>**¿Qué es `ChatGPT`?**
>
>Leamos la introducción y luego entenderemos los detalles clave.
>`ChatGPT` es un modelo lingüístico desarrollado por OpenAI.
>Está diseñado para la comprensión y generación de lenguaje natural, concretamente en un contexto conversacional.
>
>¿Verdad?
>
>Y no quiero que profundices demasiado en las palabras.
>Centrémonos en los componentes clave de esta definición que aparecen resaltados en naranja.
>En primer lugar, es lo que llamamos un Gran Modelo Lingüístico o LLM (Large Language Model).
>Y cubriremos LLM en el próximo módulo,
>pero por ahora recuerda que `ChatGPT` es un LLM.
>Y lo que significa es que es un sistema de inteligencia artificial que es realmente muy bueno con el lenguaje humano.
>En segundo lugar, está diseñado para la comprensión y generación de lenguaje natural, como
>ya he mencionado.
>
>**Dicho todo esto, ¿por qué no entramos en `ChatGPT` y hacemos una demostración de su capacidad, incluido el aspecto conversacional?**
>
>Así que aquí tengo GPT4, que es la versión de pago de esta herramienta.
>Y como puedes ver aquí, también ofrece DALL-E, que es el modelo de generación de imágenes.
>Pero como la mayoría de los espectadores utilizarán una versión gratuita, cambiaré a la 3. 5, que utilizaremos para demostrar
>sus capacidades.
>
>Así que yo le preguntaría a `ChatGPT` algo como ¿cuántos aeropuertos hay en Nueva York?>
>Lo primero que quiero que tengas en cuenta es que `ChatGPT` sólo se ha formado en contenidos hasta 2021, por lo que es posible que no pueda ofrecerte
>información actualizada, especialmente si preguntas sobre acontecimientos recientes.
>Pero en mi caso, lo pregunto sobre los aeropuertos de Nueva York, que no es una información muy reciente.
>Estos aeropuertos llevan allí mucho tiempo, así que obtuve una buena respuesta.
>Me dice que hay tres aeropuertos, y también me dice que hay aeropuertos más pequeños.
>
>**En primer lugar, es una aplicación de IA Generativa.**
>
>Está generando datos.
>Puede generar texto similar al humano.
>
>Puede responder preguntas, completar frases, traducir idiomas y realizar análisis de sentimientos.
>Y la versión 4 puede incluso generar imágenes.
>
>En resumen, `ChatGPT` es una aplicación de IA generativa.
>
>**En segundo lugar, está desarrollado por una empresa llamada OpenAI, y Microsoft tiene una muy buena inversión en OpenAI.**
>
>Es por eso que si nos fijamos en la aplicación de Microsoft, que es donde OpenAI se está utilizando mucho comercialmente,
>ya sea Bing Search, Windows Copilot, Microsoft Teams, todos ellos tienen integraciones con GPT, las aplicaciones
>iniciales, todas las que vinieron eran todas de Microsoft.
>De hecho, en lo que respecta a la nube, por ahora esta capacidad solo está disponible en Azure Cloud, que es una
>plataforma de Microsoft.
>
>**Tercer punto `ChatGPT` se entrena con miles de millones de documentos.**
>
>Por poner un ejemplo, la versión actual que vimos, la 3. 5, OpenAI no revela con cuántos datos
>se entrenó, pero la versión anterior, que era GPT 3, se entrenó con 570 GB de datos
>de texto.
>Ahora bien, si has guardado un archivo de texto o si has guardado una página web, sabrás que la mayoría están en KB inferiores.
>
>Y aquí estamos hablando de 570 GB de datos de texto.
>Así que imagina lo grande que es el volumen.
>Se ha entrenado en casi toda la Wikipedia, blogs enteros, artículos de noticias, todo lo que sea texto
>en Internet.
>
>Y si recuerdas lo que comentábamos en la nota final de nuestro último vídeo, cuantos más datos de entrenamiento,
>más posibilidades de precisión tendrá tu aplicación.
>Y eso explica por qué `ChatGPT` es tan bueno.
>
>![`ChatGPT`](images/2025-07-04_154603.png "`ChatGPT`")
>
>De hecho, ChatGPT es sólo el principio.
>
>Cada día aparecen nuevos modelos y se producen nuevos avances.
>Tal vez haya algún modelo nuevo que llegue mañana y sustituya a ChatGPT como campeón del mercado.
>Nunca se sabe.
>Pero lo que permanecerá es la idea de que todos tendremos que adoptar la IA Generativa en nuestro trabajo.
>
>Ya seamos desarrolladores, probadores, analistas empresariales, comerciales, expertos en marketing o cualquier otra persona, todos
>tendremos que aprender sobre la IA Generativa y empezar a utilizarla en nuestro trabajo.
>Y de eso va a tratar este curso.

## Section 3: Quiz

### Quiz 1: Generative AI Basics

![Quiz 1: Generative AI Basics](images/2025-07-07_093536.gif "Quiz 1: Generative AI Basics")




## Section 4: Understanding key terminologies

### 7. Introduction

![Module 2. Undertanding key terminologies](images/2025-07-08_084120.png "Module 2. Undertanding key terminologies")

### 8. LLM (Large Language Model)

>[!NOTE]
>
>**¿Qué es un LM y por qué oímos hablar tanto de él?**
>
>Para que lo entiendas de forma sencilla, a un nivel muy alto, cuando estamos en un smartphone intentando
>enviar un mensaje de texto a alguien y aparece una función de texto predictivo.
>Como puede ver, la persona teclea cant y el sistema predice las siguientes palabras: cantidad, cantina
>o cantar.
>
>Eso es más o menos lo que es un nivel muy alto.
>Pero, por supuesto, es más masivo.
>Hay mucha más precisión y también intervienen muchos otros componentes.
>Del mismo modo, cuando escribimos algo en el chat, GPT y responde por nosotros, eso también es una LM, una muy fuerte.
>
>Así que sí, el chat GPT también es un LM, por lo que los LM no son más que un tipo específico de modelos de IA que están diseñados para comprender
>y generar textos similares a los humanos.
>Por tanto, solo hay una cosa clave que debes recordar de esta diapositiva.
>
>Y eso es LM significa texto.
>Pueden comprender textos, procesarlos y generarlos.
>
>**¿Cómo funciona una LM?**
>
>Ya conocemos las redes neuronales y su capacidad para manejar escenarios complejos con eficacia gracias
>a su estructura en capas.
>Así que el cerebro de la LM es un tipo específico de red neuronal, también llamada transformadora.
>Y no vamos a profundizar en lo que es un transformador.
>Su arquitectura les permite entender el lenguaje, el
>significado y el contexto.
>Todo eso.
>
>Y lo veremos con más detalle cuando hablemos de incrustaciones más adelante.
>Pero de momento, recuerda que Transformers es un tipo de red neuronal muy buena para entender el lenguaje
>humano.
>Las palabras tienen significado, contexto, etcétera.
>Y este transformador está entrenado con muchos datos de entrenamiento, de hecho, mucho, mucho más de lo que vemos.
>
>Por ejemplo, `ChatGPT` está entrenado en Wikipedia completa y muchos más sitios web basados en texto, blogs, manuales,
>etcétera.
>Y base de este aprendizaje.
>Es realmente bueno en la comprensión del texto y la entrega de la salida.
>
>Por eso, si miras `ChatGPT`, por ejemplo, le preguntas cualquier cosa.
>Entiende tu pregunta, da buena respuesta.
>Y la razón de ello es que se está entrenando en el conjunto masivo de datos, como he mencionado.
>Y este enorme número de parámetros transformador de base, red neuronal.
>
>**Tercer y último punto.**
>
>La formación no termina aquí.
>Lo que vimos aquí fue nuestro pre-entrenamiento con el que los modelos ya vienen hechos.
>A continuación, también podemos realizar algunos ajustes finos, lo que significa que podemos ajustar aún más el LM a un conjunto de datos
>más específico y orientado a la tarea.
>Más adelante hablaremos más a fondo del ajuste fino.
>Pero por poner un ejemplo, si queremos utilizar un LM para completar o resumir textos, podemos afinarlo
>exponiéndolo a los datos relacionados con estas tareas.
>
>**¿Dónde se puede utilizar el LMS?**
>
>La respuesta es cualquier cosa que implique texto y, de hecho, ya se están utilizando en muchos de estos espacios.
>El primero es la generación de contenidos.
>Así que usted está en las ventas de publicidad de marketing en cualquier lugar.
>Podemos utilizar LMS como `ChatGPT` o Lama para nuestra generación de contenido de texto.
>
>**El segundo es el chat bot.**
>
>Este es un ámbito en el que los LMS tendrán un gran impacto.
>Cuando chateamos con el servicio de atención al cliente, LMS puede sustituir ese primer nivel de compromiso y responder a las preguntas
>por usted basándose en la documentación de la empresa.
>Y si el usuario sigue insatisfecho, puede hablar con un humano.
>
>Y por último, las preguntas y respuestas, probablemente el caso de uso más utilizado.
>Pedimos `ChatGPT` para cualquier pregunta y dar.
>Nos da la respuesta puntual.
>
>Imagina que si quiero saber quién ganó la Superbowl 2020, no tengo que entrar en Wikipedia y leer un largo
>documento.
>Puedo hacer esa pregunta y obtener una respuesta concreta en la parte de aprendizaje práctico de este curso.
>Más adelante crearemos un chatbot como este y lo verás en acción.
>Así que, chicos, estos son algunos de los casos de uso de LM.
>
>Pero recuerde que la lista no acaba aquí.
>LMS cambiará todas las formas en que interactuamos y manipulamos los datos de texto.
>Y la lista de LMS está creciendo cada día de GPT a Lama a la palma de la mano para señalar LMS para la industria automotriz industria financiera.

### 9. Prompt Engineering

>[!NOTE]
>
>Así que cada vez que se hace una pregunta o se da una instrucción y una entrada para obtener la respuesta
>deseada, eso es un prompt.
>
>Por solicitud se entiende una pregunta específica o una entrada que se da a un sistema de IA para obtener la respuesta requerida.
>
>Tenemos algunos ejemplos en la pantalla, como puedo decirle a `ChatGPT` que resuma los puntos clave de un artículo de investigación,
>o puedo decirle que escriba una historia corta, o puedo decirle a Dall-E, que es una aplicación generativa de imágenes,
>que genere imágenes de un coche amarillo.
>O puedo pedirle a GitHub Copilot, que es un compañero de generación de código, que escriba un programa en Python para sumar
>dos números.
>Así que todo esto son indicaciones.
>Así que, incluso sin conocer esta terminología, hasta ahora todos utilizábamos prompts cada
>vez que introducíamos algo en `ChatGPT`.
>
>Y en eso consiste la ingeniería rápida.
>Si quieres obtener buenas respuestas, tienes que hacer buenas preguntas.
>Así pues, la ingeniería de la rapidez consiste en elaborar consultas bien definidas para formular preguntas claras.
>Si haces preguntas concretas y precisas, preguntas sin ambigüedades, obtendrás respuestas mejores,
>precisas y pertinentes.
>
>![Mejores prácticas para _Prompt Enineering_](images/2025-07-08_090624.png "Mejores prácticas para _Prompt Enineering_")



### 10. Embeddings

>[!NOTE]
>
> Ahora bien, todo eso era estupendo y perfecto, pero si se hace una pausa y se piensa en ello, hay algo
>muy fundamental en lo que no hemos pensado.
>
>Y es que las máquinas no entienden el texto.
>Sólo entienden de números.
>
>Entonces, ¿cómo entienden estos llms lo que significa una palabra?
>
>¿O cómo pueden las máquinas reconocer la similitud entre dos textos como cuando le preguntas cuál es la capital de
>la India?
>¿Y genera la palabra Nueva Delhi?
>
>**Ahí es donde entran en escena las incrustaciones.**
>
>Por tanto, una incrustación es una representación numérica del texto.
>
>![Embeddings son representaciones numéricas del texto](images/2025-07-08_091205.png "Embeddings son representaciones numéricas del texto")
>
>Ahora bien, lo que significan estas incrustaciones sólo lo sabe el modelo de transformador que las generó.
>Esto es lo que el entrenamiento del modelo le ha enseñado a generar correctamente estas incrustaciones.
>Cómo retener el significado.
>
>**El contexto de la relación.**
>
>![Contexto de la relación](images/2025-07-08_091553.png "Contexto de la relación")
>
>Toda esta información se almacena en estas incrustaciones y sólo el la entiende.
>Lo utiliza para generar la salida.
>
>Por ejemplo, basándose en las incrustaciones, el LM sabe que la palabra I va seguida de una palabra de acción como
>comer.
>También sabe que las palabras hielo y crema van juntas.
>Por eso ves que las incrustaciones de hielo y nata son muy parecidas entre sí.
>Así es como fue entrenado.
>Y recuerda que lo ha hecho durante miles de millones de palabras.
>Ha generado billones de estas incrustaciones, y ese ha sido el entrenamiento de un modelo como
>`ChatGPT`.
>Y durante este entrenamiento, ha dominado el arte de capturar toda esta información con precisión en las incrustaciones.
>Así que cuando alguien le pida al LM que genere un texto, utilizará todo este aprendizaje que ha conseguido,
>utilizará todas estas incrustaciones que ha descubierto y las utilizará para predecir qué palabra viene
>a continuación.

### 11. Fine Tuning

>[!NOTE]
>
>Es decir, le haces una pregunta a ChatGPT sobre cualquier tema genérico y te dará una buena respuesta.
>Por tanto, los llms suelen estar preentrenados y ser muy precisos.
>Pero todo esto es formación general.
>Si desea generar información sobre una tarea específica o un conjunto de datos concreto de su organización, tendrá
>que entrenar el modelo con su conjunto de datos concreto.
>Y ahí es donde entra en juego el ajuste fino.
>
>**¿Qué es el ajuste fino?**
>
>Es como ajustar un LM preentrenado o lo que llamamos modelo base para realizar una tarea más específica.
>
>**¿Por qué lo hacemos?**
>
>Lo hacemos para obtener mejores resultados en un conjunto de datos específico, por ejemplo, un conjunto de datos médicos ajustado
>con precisión le dará mejores respuestas a sus consultas que uno básico o de vainilla.
>Ése era el qué y el por qué.
>
>**Hablemos de cómo hacer el ajuste fino.**
>
>Así que hay tres formas de afinar un modelo.
>
>* Y la primera se denomina ajuste fino autosupervisado.
>Y lo que significa es que le das a tu modelo base una gran pila de datos de entrenamiento que son específicos de tu
>dominio, y haces que el modelo aprenda de ellos.
>Así, el modelo aprende a predecir los datos que faltan.
>Como cuando dices yo helado, el modelo predice que la palabra que falta es comer.
>Ahora bien, esto es muy similar a cómo se entrena el modelo base.
>Y tienes razón.
>
>**La siguiente es lo que llamamos ajuste fino supervisado, y en realidad es una forma supervisada de aprendizaje.**
>
>Es decir, se proporcionan datos de entrenamiento detallados y etiquetados que tienen entrada y salida, y el modelo puede aprender
>de ellos.
>
>Así que tu conjunto de datos etiquetados diría algo así como, ¿cómo encuentro un hueso roto?
>Y la salida sería de rayos X.
>Así que estás dando estos conjuntos de datos etiquetados a tu modelo.
>Y va aprendiendo y mejorando en función de ellos.
>
>**Y el último es lo que llamamos aprendizaje por refuerzo.**
>
>Y en realidad el aprendizaje por refuerzo es un concepto antiguo.
>
>Es básicamente un método de aprendizaje basado en la retroalimentación.
>
>**¿Cómo habilitar GPT para responder a esa pregunta?**
>
>La respuesta es el ajuste fino.
>
>Usted entrenará el modelo con su conjunto de datos, y éste será capaz de darle ahora respuestas pertinentes para ese
>conjunto de datos.
>En eso consiste el ajuste fino.
>
>Ahora, al mismo tiempo, hablemos de lo que no es el ajuste fino.
>En primer lugar, la puesta a punto no consiste en crear algo desde cero.
>No partimos de cero.
>Partimos de un modelo básico que ya ha sido entrenado en un conjunto de datos de gran volumen, y
>sólo lo adaptamos a nuestro conjunto de datos específico.
>
>Por lo tanto, el ajuste fino es como construir sobre el conocimiento ya existente, no es reemplazar ese conocimiento.
>El ajuste fino no significa que no se necesite ningún dato.


### 12. Recap - Summary View

![12. Sumary View](images/2025-07-08_101923.png "12. Sumary View")

