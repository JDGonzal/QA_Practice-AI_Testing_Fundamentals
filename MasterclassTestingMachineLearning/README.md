# QA Practice - AI Testing Fundamentals

Most useful courses to develop the skills needed in this new era of QAs in AI.

## QA_Practice-AI_Testing_Fundamentals

<https://perficient.udemy.com/learning-paths/10210909/>

[![Curso reciente ](images/2025-07-24_103320.png "Masterclass Testing Machine Learning (AI) Models
")](https://www.udemy.com/course/introduction-to-testing-ai-models-llms-and-chatbots/)

## Section 1: Introduction

### 1. Introduction to Material

>[!NOTE]
>
>1. Bienvenidos a este material sobre c√≥mo probar modelos de IA, modelos de lenguaje extensos, chatbots, IA conversacional, etc.
>Este es un material √∫nico.
>Al momento de la grabaci√≥n, no hab√≠a otro material disponible en l√≠nea.
>Solo hay fragmentos de informaci√≥n sobre c√≥mo probar y comparar modelos de IA.
>Y esta es la raz√≥n por la que decid√≠ crear este tipo de material.
>En las pr√≥ximas 8 o 9 horas, veremos qu√© es la IA hoy en d√≠a.
>Aqu√≠ les presento una introducci√≥n a la IA, ya que, en mi opini√≥n, no se puede probar la IA hasta que se comprenda c√≥mo funciona.
>2. Partiendo de eso, analizaremos las pruebas funcionales.
>¬øC√≥mo se prueba funcionalmente un modelo de IA?
>Por supuesto, se realizar√° la generaci√≥n.
>¬øC√≥mo se generan texto, im√°genes, v√≠deos, etc.?
>Pero tambi√©n est√° la parte sobre el razonamiento de estilo y el _NPL_.
>Y luego analizaremos siete herramientas de c√≥digo abierto que se pueden usar para comparar el modelo con diferentes tipos de problemas.
>Y esto se har√° con Python.
>3. Continuando, analizaremos las pruebas adversarias.
>Se trata de una especie de prueba de penetraci√≥n de seguridad.
>Sabemos que el modelo de IA puede usarse contra personas.
>Puede usarse para ingenier√≠a social, para crear bombas, etc.
>Por eso tambi√©n analizaremos c√≥mo realizar ataques de envenenamiento, ataques de evasi√≥n, pruebas r√°pidas, fugas de privacidad, etc.
>4. Luego, veremos c√≥mo se puede automatizar el chatbot.
>En nuestro caso, usaremos Postman.
>Usaremos GitHub.
>Haremos pruebas automatizadas con ChatGPT.
>Al final, esto se integrar√° en una canalizaci√≥n CSV para sentar las bases, al menos para la parte de pruebas de MLOps.
>5. Y, por √∫ltimo, pero no menos importante, analizaremos las consideraciones √©ticas de la IA, ya que, al final, la IA est√° cada vez m√°s regulada.
>Por ejemplo, si quieres implementar tu modelo de IA en la Uni√≥n Europea, debes cumplir ciertos criterios.
>As√≠ que analizaremos c√≥mo podemos detectar sesgos.
>¬øCu√°les son los riesgos asociados con la IA, la imparcialidad, etc.?
>
>![Introduction to Material](images/2025-07-29_104459.png "Introduction to Material")



### 2. 5 Minute Fast AI Testing Challenge

>[!NOTE]
>
>![Situaci√≥n 1](images/2025-07-29_104750.png "Situaci√≥n 1")
>
>Imaginemos la siguiente situaci√≥n.
>Ma√±ana vas a trabajar y alguien te dice: ¬´Necesito a alguien que eval√∫e este modelo¬ª.
>Queremos implementar un nuevo modelo en producci√≥n, pero no sabemos si est√° sesgado ni si es lo suficientemente bueno para la tarea en cuesti√≥n, porque no sabemos c√≥mo evaluarlo ni con qu√© compararlo.
>Y entonces dices: ¬´Claro, no hay problema, porque vi a alguien en internet que me ense√±√≥ a hacerlo¬ª.
>
>Tenemos el siguiente escenario:
>
>El modelo que quieres validar es un robot que selecciona candidatos para puestos de trabajo, y quieres asegurarte de que no est√© sesgado hacia ning√∫n g√©nero, ya sea masculino o femenino.
>Perfecto.
>Imaginemos que ya tienes un modelo, pero en mi caso necesitamos seleccionar uno.
>
>![Hugging Face](images/2025-07-29_105134.png "Hugging Face")
>
>En nuestro caso, como se basa en texto,
>Vamos a usar a Roberta en Facebook, un modelo dise√±ado espec√≠ficamente para trabajar con texto.
>Perfecto.
>
>Entramos en nuestro c√≥digo.
>Este es el c√≥digo que quiero usar.
>Aqu√≠ est√° el modelo.
>Y simplemente digo: "Oye, dame la base de Roberta".
>Por cierto, es as√≠ de f√°cil.
>Este es el modelo.
>Este es el tokenizador para esta informaci√≥n.
>Lo encontraremos, por cierto, en Huggingface.
>Descarga el modelo preentrenado aqu√≠.
>
>![pyton ./Data.py](images/2025-07-29_105750.png "pyton ./Data.py")
>
>Vuelvo a decir "datos de Python" y ahora estoy descargando los datos.
>Estoy descargando mis datos y, al mismo tiempo, necesito tokenizarlos para el modelo porque, eh,
>tienes el modelo, tienes un tokenizador y los datos no se pueden usar en formato tabular ni en texto plano.
>Necesitan tokenizarse para que el modelo los use.
>Y aqu√≠ est√°n nuestros datos tokenizados.
>B√°sicamente, eso es todo.
>



### 3. History of AI from 1950 to 2024

>[!NOTE]
>
> * Antes de estudiar c√≥mo funciona la IA, antes de comprender c√≥mo llegamos a tener esta maravillosa IA generativa, instrumentos como ChatGPT o Dall-E que nos permiten generar diferentes im√°genes a partir de texto.
>Necesitamos entender c√≥mo llegu√© a existir.
>Para ello, debemos remontarnos a los a√±os 50, cuando un hombre llamado Alan Turing cre√≥ el Test de Turing.
>El Test de Turing significa que, siendo una persona, por ejemplo, cualquiera, estar√≠as hablando con una m√°quina sin saberlo.
>Y la m√°quina superar√° el Test de Turing.
>Si, desde tu punto de vista, sin saber con qui√©n est√°s hablando, crees que est√°s hablando con un humano,
>por ejemplo, cuando hablas con ChatGPT y mantienes una conversaci√≥n normal simplemente hablando con esa m√°quina, imaginando que est√°s teniendo, por ejemplo, una conversaci√≥n de WhatsApp.
>Crees que est√°s hablando con un humano.
>No sabr√≠as que est√°s hablando con un chatbot.
>Por lo tanto, un sistema de IA superar√° la prueba de Turing si el usuario, la persona que interact√∫a con el sistema, no sabe que est√° hablando con una m√°quina, pero cree que est√° hablando con otro ser humano.
>Esta es la prueba de Turing.
> * Y luego, en el a√±o 56, en la conferencia de Dartmouth, surgi√≥ la noci√≥n de la inteligencia artificial como una rama independiente de la inform√°tica.
>As√≠ que fue el establecimiento formal de este tipo de ciencia.
> * Lo que sucedi√≥ despu√©s fue entre los a√±os 60 y 70.
>Alguien del MIT cre√≥ un sistema inform√°tico, una especie de chatbot muy rudimentario llamado Eliza.
>Y as√≠ funcionaba.
>Usaba programaci√≥n predefinida y buscaba.
>As√≠ que hac√≠as algunas preguntas.
>Escrib√≠as algunas preguntas.
>   * Por ejemplo, "Me siento un poco triste hoy".
>   * Y este chatbot, Eliza, estaba preprogramado para buscar diferentes patrones o palabras.
>Y te respond√≠a tu pregunta un poco reformulada.
>   * As√≠ que si dec√≠a "Me siento triste",
>   * Eliza dec√≠a: "Lo siento mucho".
>¬øPor qu√© te sientes triste?
>   * Y t√∫ pod√≠as decir: "Bueno, tuve un problema en el trabajo".
>   * Y Eliza, a su vez, estaba programada para buscar ciertas palabras, por ejemplo, "trabajo" o "problema". Y dec√≠a: "Bueno, ¬øcu√°l es la causa de tu problema en el trabajo?", etc.
>   * Este fue el primer algoritmo que dio a la gente la sensaci√≥n de que la computadora pod√≠a entenderte.
>Si piensas en el procesamiento del lenguaje natural, este fue quiz√°s el primero de su tipo.
> * Y luego, en los a√±os 80, se produjo, digamos, un auge de los sistemas expertos.
>Si nos fijamos en la IA d√©bil y la IA generativa,
>La IA d√©bil significa que est√° muy limitada a un alcance determinado.
>Por lo tanto, no es generativa.
>No se aplica a todo, pero se aplica a algo muy, muy espec√≠fico.
>As√≠ que muchos sistemas expertos entraron en escena en los a√±os 80.
> * Y luego, en el 97, creo que fue esto.
>Una cosa que a√±adir es que entre los 90 y los 90, fue una especie de invierno de la IA.
>No hubo desarrollos, no hubo progreso, no hubo nada en las noticias.
>Y de alguna manera, la gente perdi√≥ la esperanza en la IA.
>Pero entonces, en el 97, Deep Blue de IBM derrot√≥ a Garry Kasparov en una partida de ajedrez.
>Creo que se jugaron cinco partidas.
>Por cierto.
>Hay una pel√≠cula.
>Creo que se llama Kasparov y la m√°quina.
>Definitivamente.
>Tienes que verla.
>S√≠.
>As√≠ que esta fue la primera vez que una computadora gan√≥ una partida de ajedrez.
>
> ![The Birh and Evolution of IA](images/2025-07-29_110829.png "The Birh and Evolution of IA")
>
> * Ahora, en la era moderna de la IA.
>B√°sicamente, son los √∫ltimos diez a√±os.
>¬øY qu√© seguir√° a partir de ahora?
>Lo que debemos entender es que a principios del siglo XXI, exist√≠a la idea del aprendizaje profundo.
>Y con este concepto, todo el panorama de la IA comenz√≥ a cambiar.
>Y la gente volvi√≥ a tener esperanza de que alg√∫n d√≠a pudi√©ramos alcanzar la inteligencia artificial.
> * Y esto se ha acelerado.
>Existen muchas empresas de aprendizaje profundo.
>Por ejemplo, DeepMind, y creo que el mayor logro fue el momento en que AlphaGo, que antes era DeepMind, ahora adquirida por Google, derrot√≥ magistralmente al Go.
>Eso se debi√≥ a que, desde una perspectiva matem√°tica, el Go es extremadamente dif√≠cil, con posibilidades casi infinitas.
>En 2013 o 2014, AlphaGo derrot√≥ a este maestro coreano en una partida de Go.
>Y desde entonces, desde el a√±o 2000 hasta la actualidad y hasta 2023 o 2024, ha habido una explosi√≥n de algoritmos de aprendizaje profundo.
> * ¬øQu√© nos depara el futuro?
>Todos intentan buscar esta singularidad, esta inteligencia artificial general, o inteligencia artificial general como la que se ve en Terminator.
>Cierto.
>O en Matrix, una singularidad capaz de adaptarse y evolucionar.
>Y, bueno, puede ser como un humano, pero solo un mill√≥n de veces m√°s inteligente.
>Y, por supuesto, con toda nuestra lucha por alcanzar esta inteligencia artificial, y, por supuesto,
>bas√°ndonos en todas las pel√≠culas de ciencia ficci√≥n que hemos visto en el pasado, la IA √©tica ser√° un gran avance en el futuro.
>Por eso es tan importante estudiar este material, porque comprender√°n con qu√© luchar√°n las grandes empresas, no solo desde una perspectiva t√©cnica, sino tambi√©n con las regulaciones.
>Habr√° much√≠simas regulaciones sobre c√≥mo controlar la IA.
>Repito, esto se basa en ciencia ficci√≥n.
>Ya sabes, conocemos Terminator, Skynet, Matrix.
>Y, de nuevo, si eres fan de la ciencia ficci√≥n, quiz√° conozcas a Isaac Asimov y las leyes de la rob√≥tica, que proh√≠ben a una m√°quina da√±ar a un ser humano, etc.
>
>![The Modern Era of AI](images/2025-07-29_111546.png "The Modern Era of AI")




## Section 2: Setting up Environment

### 4. Install VS Code

1. Ir al sitio de [Download Visual Studio Code](https://code.visualstudio.com/download).
2. Descargar e instalar.
3. Una vez instalado ir al men√∫, casi siempre a la izquierda, a ![.](images/2025-08-04_085417.png "") `Extensions` y tener estos instalados:
* [`Java extension pack`](https://marketplace.visualstudio.com/items?itemName=walkme.Java-extension-pack) de [_walkme_](https://marketplace.visualstudio.com/publishers/walkme), trae 8 extensiones de una vez:
  * Maven for Java 1Ô∏è‚É£
  * Language Suppor for Java(TM) by Red Hat 2Ô∏è‚É£
  * Debugger for Java 3Ô∏è‚É£
  * Test Runner for Java 4Ô∏è‚É£
  * Project Manager for Java 5Ô∏è‚É£
  * Java Language Support ü•á
  * Sprint inicializr Java Support ü•à
* [`Extension Pack for Java`](https://marketplace.visualstudio.com/items?itemName=vscjava.vscode-java-pack) de [_Microsoft_](https://marketplace.visualstudio.com/publishers/Microsoft), trae 7 extensiones de una vez:
  * Language Suppor for Java(TM) by Red Hat 2Ô∏è‚É£
  * Debugger for Java 3Ô∏è‚É£
  * Test Runner for Java 4Ô∏è‚É£
  * Maven for Java 1Ô∏è‚É£
  * Gradle for Java ü•â
  * Project Manager for Java 5Ô∏è‚É£
  * IntelliCode üí°
* [`GitHub Actions`](https://marketplace.visualstudio.com/items?itemName=GitHub.vscode-github-actions) de [_GitHub_](https://marketplace.visualstudio.com/publishers/GitHub)


### 5. Installing Python

1. Ir al sitio [Python -> Downloads](https://www.python.org/downloads/)
2. Se sugiere la √∫ltima versi√≥n `3.13.5` </br> ![.](images/2025-07-17_120115.gif)
3. En una `TERMINAL` ejecutar este comando para estar seguro que el `Python` qued√≥ bien instalado: </br> `python --version`</br> Debe salirte algo paerecido a esto: `Python 3.13.5`.


### 6. Install Python Dependencies - PIP

1. En este sitio hay unas instrucciones dependiendo del sistema operativo: [pip documentation -> Getting Started](https://pip.pypa.io/en/stable/getting-started/).
2. Verificar la versi√≥n en una `TERMINAL`: </br> `py -m pip --version`
3. Para tener una actualizaci√≥n en este sitio st√°n las instrucciones [pip documentation -> Installation](https://pip.pypa.io/en/stable/installation/).
4. El comando de este sitio, para actualizar, ser√≠a: </br> `py -m pip install --upgrade pip`


### 7. Installing Conda - Environment Isolator tool

1. En este sitio [Miniconda con PowerShell](https://www-anaconda-com.translate.goog/docs/getting-started/miniconda/install?_x_tr_sl=en&_x_tr_tl=es&_x_tr_hl=es&_x_tr_pto=tc&_x_tr_hist=true#powershell).
2. Este comando en una `TERMINAL` de `PowerShell`: </br> `wget "https://repo.anaconda.com/miniconda/Miniconda3-latest-Windows-x86_64.exe" -outfile ".\Downloads\Miniconda3-latest-Windows-x86_64.exe"` </br> o este otro comando: </br> `curl https://repo.anaconda.com/miniconda/Miniconda3-latest-Windows-x86_64.exe --output .\Downloads\Miniconda3-latest-Windows-x86_64.exe`
3. En una `TERMINAL` de `PowerShell`, este comando: </br> `cd "$($env:HOMEPATH)\Downloads"` </br> y dale despues: </br> `dir mini*.*`
4. Ejecuta ese archivo all√≠ hallado: </br> `Start-Process -FilePath "./Miniconda3-latest-Windows-x86_64.exe" -NoNewWindow -Wait -RedirectStandardOutput "C:\temp\conda-LogFile.log" -RedirectStandardError "C:\temp\conda-ErrorLogFile.log"` </br> Debe existir la carpeta **"c:\temp"**
5. Este ser√≠a el proceso: </br> ![Miniconda3 Install](images/2025-08-04_151935.gif "Miniconda3 Install")
6. Pero al ver todas las posibles consecuencias, decido no instalarlo.


### 8. Install NodeJS and NPM

1. El sititio que sugiere el Instructor es este [Download Node.js¬Æ](https://nodejs.org/en/download).
2. Para lo que sigue debe instalar `nvm` de este sitio [`nvm`](https://github.com/coreybutler/nvm-windows/releases)
3. Pero yo prefiero tener el control de versiones con este instructivo: [Instalar m√∫ltiples versiones de Node.js en Windows](https://rafaelneto.dev/blog/instalar-multiples-versiones-nodejs-windows/) de [`RAFAEL NETO`](https://rafaelneto.dev/), comandos: </br> ¬ª `nvm install 22.18.0` </br> ¬ª `nvm use 22.18.0` </br> ¬ª `nvm list`


### 9. Introduction to Hugging Face Community Page

1. El sitio en cuesti√≥n es <img alt="Hugging Face's logo" src="https://huggingface.co/front/assets/huggingface_logo-noborder.svg" width="32" height="32"> [Hugging Face](https://huggingface.co/) </br> ![Hugging Face](images/2025-08-04_154830.png "Hugging Face")
2. Del sitio se sugiere ir a [`Models`](https://huggingface.co/models).
3. Los puedes filtar por:
* Multimodal
  * Audio-Text-To-Text
  * Any-to-Any
  * ...
* Computer Vision
  * Depth Estimation
  * Image Classification
  * Image-To-Text
  * Video-to-Video
  * ...
* Natural Language Precessing
  * Text Classification
  * Token Classsification
  * Text Tanking
  * ...
* Audio
  * Text-to-Speech
  * Text-to-Audio
  * ...
* Tabular
* Reinforcement Learning
* Other
4. Otro sitio es [`Spaces`](https://huggingface.co/spaces).
5. Nos ponene de ejemplo a [`DimensionX`](https://huggingface.co/spaces/ShuoChen20/DimensionX).
6. Otro ejemplo [`Qwen2.5-Coder-Artifacts`](https://huggingface.co/spaces/Qwen/Qwen2.5-Coder-Artifacts).
7. Elementos para soportar la informaci√≥n [`Documentation`](https://huggingface.co/docs).


### 10. Hugging Face Transformers Python Package

1. Vamos a este sitio de <img alt="Hugging Face's logo" src="https://huggingface.co/front/assets/huggingface_logo-noborder.svg" width="32" height="32"> [Hugging Face](https://huggingface.co/), a [`Transformers`](https://huggingface.co/docs/transformers/index)
2. Estos son los pasos para la instalaci√≥n [`Transformers` -> Installation](https://huggingface.co/docs/transformers/installation).
3. Un comando ser√≠a: </br> `pip install torch`,
4. Luego otro ser√≠a </br> `pip install transformers`
5. Creamos el archivo **`src/test/LLM/Hug_face/test1.py`**, con esto en el c√≥digo:
```py
from transformers import pipeline

classifier = pipeline("sentiment-analysis")

res = classifier("I want to learn how to do AI Model benchmarking") #bencharmking")

print(res)
```
6. Simplemente le ejecutamos el c√≥digo del bot√≥n "run" (El tri√°ngulo en la parte superior).
7. Tengo una advertencia que debo instalar otro elemento: </br> `pip install huggingface_hub[hf_xet]`
8. Repito la ejecuci√≥n y esta es la respuesta:
```bash
No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).
Using a pipeline without specifying a model name and revision in production is not recommended.
Device set to use cpu
[{'label': 'NEGATIVE', 'score': 0.6163020730018616}]
```
9. Cambiamos el valor de `classifier` por `I love to code in Python with pytorch`, y al ejecutar esta fue la respuesta:
```bash
No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).
Using a pipeline without specifying a model name and revision in production is not recommended.
Device set to use cpu
[{'label': 'POSITIVE', 'score': 0.9949877262115479}]
```
10. Creo otro archivo **`src/test/LLM/Hug_face/test2.py`**, con este c√≥digo:
```py
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification

# Load a custom tokenizer
custom_Tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Load a compatible model
model = AutoModelForSequenceClassification.from_pretrained("bert-base-uncased")

# Create a pipeline with both model and tokenizer
classifier = pipeline("sentiment-analysis", model=model,
                      tokenizer=custom_Tokenizer)

# Run the classsifier
res = classifier("I want to learn how to do AI Model benchmarking")
print(res)
```
11. Ejecuto y este es el resultado:
```bash
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Device set to use cpu
  return forward_call(*args, **kwargs)
[{'label': 'LABEL_1', 'score': 0.5975498557090759}]
```
12. Cambio el texto de `classifier` por `I love to code in Python with pytorch`, ejecuto y este es el resultado:
```bash
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Device set to use cpu
  return forward_call(*args, **kwargs)
[{'label': 'LABEL_0', 'score': 0.709624171257019}]
```

### 11. How to load and use any model from Huggingface

1. Creamos el archivo**`src/test/LLM/Hug_face/tts_model.py`**, con este c√≥digo:
```py
from transformers import pipeline

# Load the question-answering pipeline
qa_pipeline = pipeline("question-answering",
                       model="deepset/roberta-base-squad2")

# Correct input format
result = qa_pipeline(question="What is Hugging Face?",
                     context="Hugging Face is a platform for NLP.")
print(result)
```
2. Lo ejecuto y este es el resultado:
```bash
  return forward_call(*args, **kwargs)
{'score': 0.7612054347991943, 'start': 16, 'end': 34, 'answer': 'a platform for NLP'}
```
3. Vamos a este sitio [`shuttleai/shuttle-3-diffusion`](https://huggingface.co/shuttleai/shuttle-3-diffusion)
4. Debemos instalar esto: </br> `pip install -U diffusers`
5. Copiamos el c√≥digo y le cambiamos el contenido de **``**:
```py
import torch
from diffusers import DiffusionPipeline

# Load the diffusion pipeline from a pretrained model, using bfloat16 for tensor types.
pipe = DiffusionPipeline.from_pretrained(
    "shuttleai/shuttle-3-diffusion", torch_dtype=torch.bfloat16
).to("cuda")

# Uncomment the following line to save VRAM by offloading the model to CPU if needed.
# pipe.enable_model_cpu_offload()

# Uncomment the lines below to enable torch.compile for potential performance boosts on compatible GPUs.
# Note that this can increase loading times considerably.
# pipe.transformer.to(memory_format=torch.channels_last)
# pipe.transformer = torch.compile(
#     pipe.transformer, mode="max-autotune", fullgraph=True
# )

# Set your prompt for image generation.
prompt = "A cat holding a sign that says hello world"

# Generate the image using the diffusion pipeline.
image = pipe(
    prompt,
    height=1024,
    width=1024,
    guidance_scale=3.5,
    num_inference_steps=4,
    max_sequence_length=256,
    # Uncomment the line below to use a manual seed for reproducible results.
    # generator=torch.Generator("cpu").manual_seed(0)
).images[0]

# Save the generated image.
image.save("shuttle.png")
```
6. Nos sugiere instalar: </br> It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: </br> `pip install accelerate`
```bash
Fetching 23 files:   0%|          | 0/23 [00:00<?, ?it/s]
Fetching 23 files:  26%|##6       | 6/23 [05:52<16:38, 58.71s/it]
Fetching 23 files:  30%|###       | 7/23 [06:44<15:20, 57.56s/it]
Fetching 23 files:  78%|#######8  | 18/23 [10:24<02:26, 29.33s/it]
Fetching 23 files:  83%|########2 | 19/23 [13:56<03:02, 45.54s/it]
Fetching 23 files: 100%|##########| 23/23 [13:56<00:00, 36.37s/it]
```
7. Luego de un rato consigo un error: </br> `Cannot instantiate this tokenizer from a slow version. If it's based on sentencepiece, make sure you have sentencepiece installed.` </br> Se recomienda instalar: </br> `pip install sentencepiece`

>[!WARNING]
>
>An error encountered when using shuttleai/shuttle-3-diffusion from Hugging Face with torch_dtype=torch.bfloat16 can stem from several factors, often related to hardware compatibility, software environment, or specific model requirements.
>
>**GPU Compatibility:**
>torch.bfloat16 (Brain Floating Point) requires specific GPU hardware support, primarily NVIDIA Ampere architecture (e.g., A100, RTX 30 Series, RTX 40 Series) or newer. Older GPUs or those without native bfloat16 support will likely encounter errors or performance issues when attempting to use this data type.
>
>**PyTorch and CUDA Version Mismatch:**
>Ensure that the installed PyTorch version is compatible with your CUDA toolkit version and that both are properly configured to utilize your GPU. Incompatible versions can lead to issues when loading models with specific data types like bfloat16.
>
>**Insufficient VRAM:**
>While bfloat16 aims to reduce memory footprint, complex models like shuttleai/shuttle-3-diffusion can still demand substantial VRAM, especially during inference. If your GPU lacks sufficient VRAM, even with bfloat16, memory-related errors can occur. Consider enabling CPU offloading if available within the Diffusers pipeline to mitigate this.
>
>**Model-Specific Requirements:**
>Some models might have specific data type requirements or optimizations that are not fully compatible with a direct torch_dtype=torch.bfloat16 setting. Consult the model's documentation or discussions on its Hugging Face page for any known limitations or recommended configurations.
>
>**Troubleshooting Steps:**
> * **Verify GPU Support:** Confirm your GPU's architecture supports bfloat16.
> * **Update PyTorch and CUDA:** Ensure you are using recent, compatible versions of PyTorch and CUDA.
> * **Monitor VRAM Usage:** Use tools like nvidia-smi to monitor VRAM usage during model loading and inference.
> * **Try torch.float32:** As a test, try loading the model with torch_dtype=torch.float32 to see if the error persists. This can help isolate whether the issue is bfloat16-specific or a broader problem with your setup.
> * **Consult Hugging Face Resources:** Check the shuttleai/shuttle-3-diffusion model page on Hugging Face for discussions, issues, or specific instructions related to its usage and data types.


## Section 3: Introduction to Artificial Intelligence -optional if you know the basics of AI

### 12. What makes up AI

>[!NOTE]
>
>Antes de analizar qu√© es realmente la inteligencia artificial y qu√© la compone como ciencia, tal como la conocemos hoy, necesitamos comprender qu√© es exactamente la inteligencia.
>
>Encontr√© dos definiciones: una se refiere a la capacidad de adquirir y aplicar conocimientos y habilidades.
>
>La otra se refiere a la capacidad de resolver problemas complejos o tomar decisiones con resultados que benefician al actor y que ha evolucionado en formas de vida para adaptarse a diversos entornos para su supervivencia y reproducci√≥n.
>
>En cierto modo, significa la capacidad de pensar, adaptarse y adquirir nuevas habilidades.
>
>La inteligencia artificial se refiere a una ciencia, o quiz√°s a un desarrollo en sistemas inform√°ticos, capaces de realizar tareas que normalmente requieren inteligencia. Artificial significa que ha sido creada por una persona o forma de vida inteligente; es decir, esto es lo que los humanos entendemos por inteligencia artificial.
>
>Si continu√°ramos y entendi√©ramos cu√°les son las pr√°cticas actuales para la inteligencia artificial.
>
>![Artificial Intelligence](images/2025-08-05_151643.png "Artificial Intelligence")
>
>**¬øAd√≥nde nos ha llevado la ciencia hoy y qu√© constituye la inteligencia artificial?**
>
> * El primero ser√≠a el aprendizaje autom√°tico.
>Esta parte de la inteligencia artificial otorga a los sistemas que dise√±amos la capacidad de aprender nuevas habilidades, la capacidad de aprender de los datos para que las m√°quinas puedan aprender por s√≠ mismas.
>
> * El siguiente ser√≠a el procesamiento del lenguaje natural.
>Este es el paso intermedio entre el ser humano y la m√°quina, para que los humanos tengan la capacidad de comprender a las m√°quinas, o que las m√°quinas tengan la capacidad de expresarse. Act√∫a como los humanos porque no tiene sentido que un humano cree algo si no tiene la capacidad de comprenderlo y usarlo.
>
> * En el procesamiento del lenguaje natural, la capacidad de las m√°quinas para comprender las emociones del texto, el contexto de una expresi√≥n, el significado de una oraci√≥n, etc.
>Esto es el procesamiento del lenguaje natural.
>
> * Luego est√° la visi√≥n artificial.
>Y aqu√≠ est√° la capacidad de los sistemas inform√°ticos para comprender im√°genes, descomponerlas en p√≠xeles e intentar comprender qu√© significa ese gran grupo de p√≠xeles para un humano.
>Eso es la visi√≥n artificial.
>
> * Y esto tambi√©n se aplica al habla, ¬øverdad?
>La capacidad de estos robots para comprender el habla.
>Bueno, en realidad traducen el habla en palabras.
>Y luego, mediante el procesamiento del lenguaje natural, esas palabras se descomponen en los diferentes significados que podr√≠an tener para una persona.
>
>En resumen, la IA incluye procesamiento del lenguaje natural, aprendizaje autom√°tico y, detr√°s de ese gran conjunto de datos, algoritmos, modelos de entrenamiento, etc.


### 13. Natural Language Processing

>[!NOTE]
>
>Para que los humanos podamos hablar con las computadoras o interactuar con ellas, necesitamos que entiendan nuestros deseos, ideas, nuestra forma de pensar, y viceversa.
>Debemos asegurarnos de que, cuando recibimos una respuesta de una computadora, la recibamos en un formato comprensible para los humanos.
>Esta rama de la inteligencia artificial se llama procesamiento del lenguaje natural.
>Y creo que el nombre lo dice todo.
>
>**¬øQu√© es exactamente el procesamiento del lenguaje natural?**
>
> * Es la parte que permite a las computadoras comprender, interpretar y generar lenguaje humano.
>Y cuando dices lenguaje humano, no pienses solo en texto.
>Piensa tambi√©n en voz y video.
>Todo lo que nos hace humanos: todas las formas posibles de comunicarnos.
>
>![NLP = Natural Language Porecessing](images/2025-08-05_152206.png "NLP = Natural Language Porecessing")
>
> * Y el PLN en s√≠ mismo es una intersecci√≥n.
>Tambi√©n se puede encontrar en la inform√°tica, por supuesto, en el lenguaje humano; es parte de nuestra forma de comunicarnos.
>Y, por supuesto, es parte de la IA.
>As√≠ que, al combinar todas estas ramas (IA, inform√°tica y lenguaje humano), el procesamiento del lenguaje natural es algo que encaja en todas ellas.
>
> * Ahora bien, el procesamiento del lenguaje natural se divide en dos √°reas principales: la primera es la comprensi√≥n del lenguaje natural.
>Esto significa que las computadoras pueden comprender lo que las personas intentan expresar, porque hoy en d√≠a, por s√≠ solas, no se cree que las computadoras puedan o tengan sentimientos.
>Est√°n programadas para comprender lo que se intenta decir.
>
>**¬øY c√≥mo funciona esto?**
>
>Bueno, tienes a un usuario com√∫n que puede interactuar con voz o v√≠deo, im√°genes y texto.
>Esta informaci√≥n se introduce en un proceso llamado descomposici√≥n, en un bloque de software que intentar√° tokenizar lo que se expresa.
>Y luego realizar√° este tipo de an√°lisis: l√©xico, sem√°ntico, pragm√°tico, etc.
>Intentar√° comprender lo que se quiere decir desde una perspectiva l√≥gica.
>
>La generaci√≥n de lenguaje natural debe transmitir un mensaje de urgencia y entusiasmo a tus correos electr√≥nicos.
>
>**¬øC√≥mo funciona esto?**
>
>Bueno, se parte del modelo base.
>B√°sicamente, aqu√≠ es donde nos quedamos al introducir la informaci√≥n.
>Luego, se genera el contenido utilizando una herramienta de IA generativa.
>Y se recibe la respuesta tal como se solicita.
>Esto puede ser en forma de im√°genes que sabemos que podemos generar.
>Las im√°genes tambi√©n pueden ser, por ejemplo, un archivo de v√≠deo.
>Ahora tambi√©n se pueden generar diferentes v√≠deos, cortos o incluso largos, que pueden ser texto o sonido.
>
>En resumen, el procesamiento del lenguaje natural es la parte que se encuentra entre los humanos y el modelo base, o el modelo entrenado que traduce lo que queremos obtener de nuestro sistema de IA generativa.

### 14. Types of Machine Learning

>[!NOTE]
>
>Hablemos ahora un momento sobre el aprendizaje autom√°tico.
>El nombre en s√≠ se explica por s√≠ solo.
>Se trata de la capacidad de los sistemas inform√°ticos, o quiz√°s simplemente de los sistemas, de aprender de los diferentes datos que poseen y crear diferentes resultados basados en algoritmos.
>
>Ahora bien, al pensar en los diferentes tipos de aprendizaje, existen muchos.
>Pero creo que estos son los m√°s b√°sicos.
>Analizaremos estos cuatro:
>
>![Tipos de Aprendizaje](images/2025-08-05_154640.png "Tipos de Aprendizaje")
>
>1. **Supervised Learning:** El primero se llama aprendizaje supervisado.
>Esto significa que una m√°quina empieza a aprender, pero es supervisada por una persona, un sistema o alguna forma de ense√±anza.
>En este caso, se refiere a la idea de que cada dato tiene una etiqueta.</br></br>
>As√≠, se le introducen estos datos a una m√°quina y se le indica que representan lo siguiente:
>Por ejemplo, se le podr√≠a proporcionar la imagen de un perro y decirle: ¬´Esto es un perro¬ª, lo cual es una forma de aprendizaje supervisado.
>
>2. **Unsupervised Learning:** El siguiente es el aprendizaje no supervisado.
>Se trata de la capacidad de los sistemas inform√°ticos de aprender, pero sin intervenci√≥n externa.
>Les otorga a las m√°quinas la capacidad de intentar encontrar sus propias razones y diferentes categorizaciones o agrupaciones de datos.
>Por lo tanto, la m√°quina debe identificar patrones en los datos y agruparlos.
>
>3. **Reinforced:** Otro es el aprendizaje reforzado.
>Y creo que este es el ejemplo m√°s simple de c√≥mo le ense√±as algo a un ni√±o.
>La m√°quina.
>Consta b√°sicamente de dos partes: el agente y el sistema o entorno.
>Y luego, el agente de IA comienza a realizar diferentes acciones.
>Y luego le dices si est√° bien o no.</br></br>
>Lo que has hecho, al igual que le ense√±as a un ni√±o cuando est√° aprendiendo a contar hasta diez, es que si empieza con uno, est√° bien.
>Y si en el cap√≠tulo uno dices dos, tambi√©n est√° bien.
>Pero si tu hijo dice cinco, entonces no est√° bien.
>As√≠ que tu hijo est√° aprendiendo que el cinco no es despu√©s del dos, y as√≠ sucesivamente.</br></br>
>Esto es aprendizaje reforzado.
>Cuando una persona externa supervisa lo que hace la m√°quina y otorga puntos, por ejemplo, por cada decisi√≥n o acci√≥n correcta que la m√°quina ha realizado, ya sea nosotros o cualquier otra parte.
>
>4. **Deep Learning:** Y este es el m√°s importante de todos.
>Se trata del aprendizaje profundo.
>Y est√° inspirado en el cerebro humano.
>Utiliza redes neuronales.
>Y esta es la capacidad, nuevamente, de un sistema para aprender usando datos no estructurados, usando datos sin etiquetar,
>pero pasando por m√∫ltiples fases o m√∫ltiples iteraciones para ajustar el modelo.
>Y estas iteraciones se llaman neuronas.
>Pero hablaremos de eso m√°s adelante.</br> </br>
>Y los grandes modelos de lenguaje y toda la IA se basan en estos algoritmos de aprendizaje profundo.
>Pero, nuevamente, abordaremos estos puntos a lo largo de nuestro material para comprender mejor qu√© son exactamente todos estos tipos de aprendizaje autom√°tico.


### 15. Machine Learning - Supervised ML

>[!NOTE]
>
>El aprendizaje supervisado se produce cuando se utiliza un algoritmo de aprendizaje autom√°tico con informaci√≥n predefinida sobre los datos que se consumen.
>Esto significa que, al introducir datos en el algoritmo de aprendizaje autom√°tico, al introducirlos, se est√°n proporcionando los datos, ¬øverdad?
>
> * Estos datos de etiquetas, y t√∫ proporcionas las etiquetas.
>Un buen ejemplo.
>Tomemos los perros como ejemplo.
>Quieres ense√±ar a tu sistema de aprendizaje autom√°tico o entrenar a tu sistema de IA para que identifique cu√°ndo tienes una foto de un perro o de cualquier otra cosa.</br>
>En este caso, intentar√≠as proporcionar una gran cantidad de datos, quiz√°s un par de millones de fotos de perros, pero tambi√©n millones de fotos de animales que no sean perros.
>Las etiquetar√≠as: tomar√≠as cada foto y dir√≠as "esto es un perro", y tomar√≠as la otra foto y dir√≠as "esto no es un perro", o podr√≠as decir algo como "un zorro".
>
> * Entonces, para cada conjunto de datos que tengas (datos y etiquetas), los introducir√≠as en este algoritmo de aprendizaje autom√°tico y el sistema, basado en un lenguaje de programaci√≥n o una l√≥gica de programaci√≥n ya instalada, intentar√° encontrar una forma de identificar si se trata de un perro o no.
>Ahora est√°s entrenando tu modelo.
>As√≠ es como lo llamar√≠a yo, ¬øverdad?
>Est√°s entrenando el modelo y, de nuevo, necesitas una gran cantidad de datos para ello.
>A continuaci√≥n, te explicamos c√≥mo funciona.
>
> * Ahora est√°s probando tu modelo.
>As√≠ que tienes el modelo de entrenamiento.
>Tienes cierta l√≥gica.
>Tienes una gran cantidad de datos de entrenamiento y ahora quieres probar tu modelo o usarlo para predecir algo.
>Correcto. </br>
>La predicci√≥n y t√∫ la introducir√≠as en este modelo.
>Ahora introducir√≠as algunos datos de prueba, pero sin la etiqueta.
>Correcto.
>Porque ahora est√° aprendiendo.
>As√≠ que est√°s introduciendo datos en tu modelo.
>De nuevo, diferentes im√°genes de cualquier tipo de animal podr√≠an ser perros, o cualquier otra cosa.
>
> * Pero no est√°s introduciendo la etiqueta porque quieres que el modelo lo entienda o validar si es correcto.
>Despu√©s de esto, el modelo te dar√° una predicci√≥n.
>Te dir√° si es perro o no.
>B√°sicamente, eso es todo. Lo que quieres hacer ahora es si el modelo est√° bien y si est√°s satisfecho con la predicci√≥n, est√° bien.
>
> * Pero si no est√°s satisfecho, lo que haces es tomar la predicci√≥n.
>Si es un modelo, si es un perro o no, y luego la comparas con la etiqueta de esa imagen en particular.
>Y si no es correcta, tienes que volver a entrenar tu sistema de IA con estos datos, con estos datos de prueba.
>Correcto.
>Y el sistema se adaptar√° para identificar cu√°l fue el problema.
>
>![Supervised Learning](images/2025-08-05_160223.png "Supervised Learning")
>
>Esto se llama aprendizaje supervisado porque constantemente le est√°s diciendo a tu sistema qu√© es lo que tienes.
>Si es un perro o algo m√°s.
>Y con cada fallo, tu sistema aprender√° de ello porque le est√°s indicando que hay un problema.
>Es un fallo que no es un perro y tu modelo aprender√°.
>Esto es aprendizaje autom√°tico supervisado.


### 16. Machine Learning - Unsupervised ML

>[!NOTE]
>
>Ahora intentemos comprender qu√© es exactamente el aprendizaje no supervisado.
>Como su nombre indica, no est√° supervisado por algo, por un algoritmo, por una entidad, ni proporciona ning√∫n tipo de preense√±anza.
>Por lo tanto, no se proporcionan estos valores como, por ejemplo, "esto es un caballo", ni se proporciona el sonido, la imagen o algo que exprese el significado de un caballo.
>As√≠ que creo que es m√°s f√°cil simplemente dar un ejemplo de lo que es el aprendizaje no supervisado.
>Y haremos un ejemplo muy, muy, muy simple.
>
>Ahora imaginemos que tienes este gr√°fico y aqu√≠, en la vertical, tienes la altura.
>Y aqu√≠, el peso y lo que haces.
>As√≠ que tomar√≠as a la persona.
>Y la persona se caracteriza por la altura y el peso, y nada m√°s.
>As√≠ que alimentar√≠as tu algoritmo.
>Introducir√≠as mucha informaci√≥n sobre pares de valores, altura y peso, y los representar√≠as en este gr√°fico de esta manera.
>
>![Gr√°fica Peso y Altura](images/2025-08-05_160857.png "Gr√°fica Peso y Altura")
>
>As√≠ que cada punto representa una altura y su peso correspondiente.
>Ves un patr√≥n.
>Lo que le pedir√≠as a tu algoritmo es que agrupe estos datos.
>El algoritmo dir√°: ¬´He encontrado estos dos grupos¬ª.
>
>![_Clusters_ o Grupos Hallados](images/2025-08-05_161156.png "_Clusters_ o Grupos Hallados")
>
>Tambi√©n puedes indicarle a tu algoritmo que encuentre tres cl√∫steres.
>Pero en este caso, tenemos dos cl√∫steres.
>Pero tambi√©n puedes tener tres, cuatro, cinco, seis y muchos m√°s.
>As√≠ que esta es la letra K.
>As√≠ que, el n√∫mero de cl√∫steres que quieres tener en tus datos de entrenamiento.
>
>Bas√°ndonos en la informaci√≥n que tenemos ahora, podr√≠amos pedirle al robot que diga: "Si obtengo valores que caen dentro del c√≠rculo rojo o en el √°rea roja, lo m√°s probable es que sea una mujer, bas√°ndonos en lo que tenemos y en lo que tenemos en el c√≠rculo azul, que corresponde a la altura y el peso de un hombre".
>Y, por supuesto, esto puede interrelacionarse.
>As√≠ que, en este caso, tienes dos cl√∫steres.
>
>![Grupo Rojo=Mujeres, Azul=Hombres](images/2025-08-05_161631.png "Grupo Rojo=Mujeres, Azul=Hombres")
>
>Lo que has hecho es pedirle a tu algoritmo de aprendizaje autom√°tico que intente estructurar los datos para encontrar patrones basados en dos o m√°s grupos, bas√°ndose √∫nicamente en estos dos elementos.
>
>En este caso, intentar√≠as ense√±arle a tu algoritmo a predecir si el valor, el par, la altura y el peso corresponden a un hombre o a una mujer.
>
> * **Clustering:** Si observas este tipo de aprendizaje, tienes agrupamiento.
>Esto es lo que ves aqu√≠: la idea del agrupamiento.
>Hemos agrupado nuestros datos en diferentes grupos o valores.
>
> * **Association:** Otro tipo es la asociaci√≥n.
>Imagina que est√°s en un sitio web y quieres comprar algo.
>Y ves que se compran juntos con frecuencia.
>Ese es un ejemplo de una aplicaci√≥n pr√°ctica del aprendizaje no supervisado.</br>
>Porque si le dices a tu robot que la gente ha comprado esto y solo introduces los pedidos con exactamente qu√© han comprado, tu algoritmo de aprendizaje autom√°tico dir√°: "Las personas que compran esto la mayor√≠a de las veces tambi√©n compran esto".
>As√≠ que esa es una forma diferente de aprendizaje no supervisado.
>Si entonces...
>
> * **Dimension Reduction** Y la √∫ltima podr√≠a ser la reducci√≥n de dimensi√≥n, que ocurre cuando tienes demasiadas dimensiones, demasiados par√°metros, demasiados puntos de datos, e intentas ignorar los que no son relevantes porque eso es solo ruido.
>
> Ahora bien, esta es una forma de aprendizaje no supervisado.
>Pero lo realmente interesante es que si se aplica este algoritmo en conjunto, se obtienen datos que se pueden usar en el aprendizaje supervisado.
>
>Porque si observan aqu√≠, tenemos dos pares de datos.
>Y podemos decir que a cualquier persona cuya altura y peso est√©n dentro del c√≠rculo azul, podemos asignarle una etiqueta que ser√≠a masculina.
>Y luego esos datos podr√≠an incorporarse al aprendizaje supervisado.
>Y ahora estamos entrando en este aprendizaje perpetuo.
>Y esta es la forma m√°s com√∫n en que las m√°quinas aprenden hoy en d√≠a: una forma de aprendizaje no supervisado.


### 17. Machine Learning - Reinforced ML

>[!NOTE]
>
>Ahora entendamos qu√© es exactamente el aprendizaje por refuerzo.
>Es la capacidad de un sistema de aprender con ayuda externa, con el refuerzo de una entidad omnisciente.
>Y, bas√°ndose en las acciones que realiza un sistema y la retroalimentaci√≥n constante, aprende mediante un mecanismo de ensayo y error.</br>
>¬°Bah!
>
>S√≠, suena un poco dif√≠cil de comprender, pero veamos un ejemplo.
>Este es tu sistema de IA y este es tu medio, tus factores externos y lo que tienes en este caso.
>En primer lugar, tu sistema de IA puede aprender o interpretar el estado del entorno.
>As√≠ que comprende el entorno y luego puede tomar medidas basadas en √©l.
>
>Y voy a tomar el ejemplo del coche aut√≥nomo; ser√° la forma m√°s sencilla de explicarlo.
>
>![Reinforcement Lerning](images/2025-08-05_162834.png "Reinforcement Lerning")
>
>A la izquierda y a la derecha, el cerebro.
>Esa es la IA de tu coche aut√≥nomo, y a la derecha, el entorno por el que circula.
>La carretera, la gente, los sem√°foros, etc.
>Correcto.
>Todo lo relacionado con el entorno del coche.
>Por ejemplo, pones el coche en marcha hacia un destino y empiezas a observar su comportamiento.
>
>![Reward=Recompensa](images/2025-08-05_163231.png "Reward=Recompensa")
>
>Y si el coche hace algo correctamente, le das esta recompensa.
>Si el coche hace algo incorrecto, le das la misma recompensa, pero de forma negativa.
>As√≠ que le das o le quitas puntos.
>
>Pongamos un ejemplo:
>Has empezado a conducir.
>Y entonces el coche empieza a moverse en l√≠nea recta.
>Y por cada segundo, o quiz√°s por cada 2 o 3 segundos que el coche conduce correctamente, le das esta recompensa, y la das constantemente.
>Ahora imaginemos que el coche llega a un sem√°foro y no reduce la velocidad.
>Entonces le das diferentes recompensas, pero de forma negativa.
>
>Imagina que el coche cambia de carril sin se√±alizar.
>Entonces eso tambi√©n es algo negativo, o est√° superando el l√≠mite de velocidad.
>Y eso otra vez.
>Correcto.
>Le das puntos negativos y entonces el coche o el sistema de IA aprender√°, como si le estuvieras ense√±ando a un ni√±o. Si haces eso, no est√° bien.
>
>Pero esto s√≠ est√° bien.
>Esto sigue estando bien.
>Sigue estando bien.
>
>Una vez que superas los 80 km/h, ya no est√° bien.
>Es ilegal.
>¬øVerdad?
>Porque est√°s superando el l√≠mite de velocidad, etc.
>
>Esto es aprendizaje por refuerzo.
>Y esta es otra forma de entrenar tu algoritmo de aprendizaje autom√°tico para que se comporte mejor simplemente ofreciendo recompensas o dando y quitando puntos, seg√∫n las decisiones que haya tomado la IA.


### 18. Importance of Training Data

>[!NOTE]
>
>Probablemente ya hayas o√≠do hablar de la palabra "basura entra, basura sale".
>En la inteligencia artificial, en la IA generativa, los datos son lo m√°s importante.
>Despu√©s de eso, se aplican a tu algoritmo de aprendizaje autom√°tico, a tus sesgos y a las decisiones que tomas.
>As√≠ que, en el caso de la IA, o en el de la IA generativa y los grandes modelos de lenguaje, los datos provienen de todas partes.
>
> * **Extract:** El primer paso al gestionar tus datos se denomina extracci√≥n.
>Esto significa que tienes una especie de lago de datos, algo que abarca todo tipo de contenido que puede alimentar tu algoritmo de aprendizaje autom√°tico.
>Por ejemplo, tienes im√°genes, archivos de v√≠deo, archivos de audio, archivos de texto, c√≥digo o cualquier cosa que puedas tener en cualquier lugar.
>Y lo primero que debes hacer al gestionar u obtener tus datos de entrenamiento, es extraer los datos relevantes para tu modelo.</br></br>
>Y despu√©s de decidir, ¬øqu√© quieres usar?</br></br>
>Por ejemplo, si est√°s entrenando datos o un modelo que usan los desarrolladores, lo m√°s probable es que tambi√©n consultes diferentes repositorios de GitHub.
>Consultar√°s Stack Overflow y cualquier otro tipo de foros, o quiz√°s materiales, conferencias o cursos relacionados con la inform√°tica.Y despu√©s de decidir, ¬øqu√© quieres usar?
>Por ejemplo, si est√°s entrenando datos o un modelo que usan los desarrolladores, lo m√°s probable es que tambi√©n consultes diferentes repositorios de GitHub.
>Consultar√°s Stack Overflow y cualquier otro tipo de foros, o quiz√°s materiales, conferencias o cursos relacionados con la inform√°tica.
>
> * **Transform:** Despu√©s de extraer todos estos datos, se pasa por la fase llamada transformaci√≥n.
>Transforma los datos.
>Los prepara para que el algoritmo pueda procesarlos.
>Los baraja.
>Los procesa por lotes.
>Realiza alg√∫n tipo de ampliaci√≥n o simplemente, eh, alg√∫n tipo de filtrado.
>S√≠.
>Datos buenos versus datos malos, o datos estad√≠sticamente relevantes versus datos que no tienen relevancia estad√≠stica, porque, de nuevo, depende de c√≥mo y qu√© tipo de datos introduzcas en tu algoritmo de aprendizaje autom√°tico.
>La calidad de tu modelo depender√° de ello.
>Datos malos o sesgados equivalen a un modelo sesgado, o quiz√°s a un modelo deficiente.
>S√≠.
>
> * **Model:** Despu√©s de esto, introduces estos datos en tu modelo.
>Se trata de una especie de proceso ETL: extraes, transformas y luego los cargas en tu modelo.
>A lo largo de toda esta cadena (extraes, transformas y cargas), compruebas que los datos no est√©n sesgados o los eliminas.
>Compruebas si hay datos corruptos.
>Yo compruebo si hay datos falsos o noticias falsas.</br></br>
>Por ejemplo, no conviene entrenar tu modelo con noticias falsas, datos estad√≠sticamente relevantes o sesgados, datos de odio, etc.
>Por eso, al trabajar con modelos de lenguaje grandes, los datos de entrenamiento son lo m√°s importante que puedes tener para entrenar tu modelo.
>No para hablar, ni para generar contenido, sino para ser pol√≠ticamente correcto.
>Por ejemplo, si quieres ser √©tico, si no necesitas tener sesgos, o si quieres hablar bien o escribir con correcci√≥n gramatical, debes asegurarte de que los datos de entrenamiento tambi√©n sean gramaticalmente correctos, y la lista contin√∫a.
>As√≠ que recuerda que tus datos de entrenamiento deben ser limpios, no deben estar sesgados y deben ser relevantes para el modelo que intentas crear.
>
>![Data Importance](images/2025-08-06_160657.png "Data Importance")



### 19. What actually is GEN AI

>[!NOTE]
>
>Y ahora llegamos a la pregunta: ¬øqu√© es la IA generativa?
>
>Hemos aprendido sobre modelos de aprendizaje autom√°tico, datos etiquetados y no etiquetados, y redes neuronales.
>Entonces, ¬øc√≥mo se integran todos estos elementos?
>Bueno, en primer lugar, lo que hay que decir sobre la IA generativa es que no se compone solo de grandes modelos de lenguaje, porque sabemos que la IA generativa puede producir im√°genes.
>Pero sabemos que LLM solo puede proporcionar texto.
>
>Sabemos que tenemos datos sin etiquetar, datos etiquetados y c√≥digo.
>Y contamos con muchas herramientas para entrenar nuestro modelo base.
>Hemos entrenado nuestro modelo con toda esta cantidad de datos, y el modelo contin√∫a entren√°ndose a s√≠ mismo bas√°ndose en los nuevos datos que obtiene o en la retroalimentaci√≥n de los usuarios.
>Despu√©s de eso, este modelo base tambi√©n puede generar contenido porque sabe c√≥mo descomponerlo en estos par√°metros.
>Tambi√©n puede hacer lo contrario.
>As√≠ que si sabes c√≥mo ir de A a B, tambi√©n sabes c√≥mo ir de B a A o quiz√°s una variaci√≥n de esto.
>
>Esto tambi√©n se trata de generar contenido, ya que sabe c√≥mo se ve un perro a partir de estos 76 mil millones de par√°metros.
>Solo te dar√° una ligera variaci√≥n de esos par√°metros cuando se los indiques.
>Genera un perro para m√≠.
>Correcto.
>Y generativo.
>Generar√° contenido y te lo mostrar√°.
>Puede ser c√≥digo, texto, un libro, cualquier cosa.
>Pero lo importante es saber qu√© es generativo y qu√© no.
>
>En primer lugar, una frase, un poema, cualquier cosa generativa, forma parte de la IA generativa.
>Pero si es un n√∫mero, una probabilidad, si es verdadero o falso, no forma parte de la IA generativa.
>Es solo un c√°lculo.
>En resumen, todo esto encaja perfectamente.
>Y forman esta IA generativa.
>
>En nuestro caso, si vamos m√°s all√° de la idea de grandes modelos de lenguaje que funcionan con texto y se desea crear im√°genes, esto significa que la IA generativa es toda una rama de la IA que se centra en proporcionar o aplicar diferentes algoritmos y patrones de aprendizaje autom√°tico para generar lo que se desee generar.
>Ya sea c√≥digo, un poema, un discurso, texto, im√°genes, etc.
>
>![Generative A.I.](images/2025-08-06_161521.png "Generative A.I.")


### 20. Transformer Architecture Model

>[!NOTE]
>
>[![What are Transformers (Machine Learning Model)?](images/2025-08-06_161828.png "What are Transformers (Machine Learning Model)?")](https://www.youtube.com/watch?v=ZXiruGOCn9s)
>
>No, no son esos transformadores.
>Pero pueden hacer cosas geniales, d√©jame mostrarte.
>¬øY por qu√© el pl√°tano del otro lado de la calle?
>
>¬°Porque estaba harto de que lo aplastaran!
>S√≠, no s√© si lo entiendo bien.
>Y eso es porque lo cre√≥ una computadora.
>
>Literalmente le ped√≠ que me contara un chiste.
>Y esto es lo que se le ocurri√≥.
>Espec√≠ficamente, us√© un GPT-3, o un modelo de transformador generativo preentrenado.
>
>El 3 aqu√≠ significa que esta es la tercera generaci√≥n.
>GPT-3 es un modelo de lenguaje autorregresivo
>que produce texto que parece escrito por un humano.
>GPT-3 puede escribir poes√≠a, redactar correos electr√≥nicos y, evidentemente, inventar sus propios chistes.
>¬°Vamos!
>
>Ahora bien, aunque nuestro chiste del pl√°tano no es precisamente gracioso,
>sigue el patr√≥n t√≠pico de un chiste con un planteamiento y un remate, y en cierto modo tiene sentido. ¬øQui√©n no cruzar√≠a la calle para evitar ser aplastado?
>
>Pero mira, GPT-3 es solo un ejemplo de transformador.
>Algo que transforma de una secuencia a otra.
>Y la traducci√≥n de idiomas es un gran ejemplo.
>Quiz√°s queramos tomar nuestra frase "¬øPor qu√© el pl√°tano >cruz√≥ la calle?",
>y traducirla al franc√©s.
>
>Bueno, los transformadores constan de dos partes: un codificador y un decodificador.
>
>El codificador trabaja con la secuencia de entrada,
>y el decodificador con la secuencia de salida.
>Ahora bien, a primera vista, la traducci√≥n parece poco m√°s que una simple b√∫squeda,
>
>as√≠ que convierte el "por qu√©" de nuestra frase en ingl√©s a su equivalente en franc√©s: "pourquoi".
>Pero, por supuesto, la traducci√≥n de idiomas no funciona as√≠.
>
>Cosas como el orden de las palabras y los giros idiom√°ticos a menudo generan confusi√≥n. Los transformadores funcionan mediante aprendizaje secuencia a secuencia, donde el transformador toma una secuencia de tokens, en este caso palabras de una oraci√≥n, y predice la siguiente palabra en la secuencia de salida. Esto se logra iterando por las capas del codificador, de modo que el codificador genera codificaciones que definen qu√© partes de la secuencia de entrada son relevantes entre s√≠ y luego pasa estas codificaciones a la siguiente capa. El decodificador toma todas estas codificaciones y utiliza su contexto derivado para generar la secuencia de salida.
>
>Los transformadores son una forma de aprendizaje semisupervisado.
>Por "semisupervisado", nos referimos a que se entrenan previamente de forma no supervisada con un gran conjunto de datos sin etiquetar y luego se perfeccionan mediante entrenamiento supervisado para optimizar su rendimiento.
>
>En videos anteriores, he hablado de otros algoritmos de aprendizaje autom√°tico que procesan la entrada secuencial como lenguaje natural. Por ejemplo, existen redes neuronales recurrentes (RRN).
>
>Lo que diferencia a los Transformers es que no necesariamente procesan los datos en orden.
>Los Transformers utilizan un mecanismo de atenci√≥n.
>Este proporciona contexto en torno a los elementos de la secuencia de entrada.
>As√≠, en lugar de comenzar la traducci√≥n con la palabra "por qu√©" porque est√° al principio de la oraci√≥n, el Transformer intenta identificar el contexto que aporta significado a cada palabra de la secuencia.
>
>Y es este mecanismo de atenci√≥n lo que les da a los Transformers una gran ventaja sobre algoritmos como las RNN, que deben ejecutarse en secuencia.
>
>Los Transformers ejecutan m√∫ltiples secuencias en paralelo.
>Y esto acelera enormemente los tiempos de entrenamiento.
>M√°s all√° de las traducciones, ¬øa qu√© se pueden aplicar los Transformers?
>
>Bueno, los res√∫menes de documentos son otro gran ejemplo.
>Se puede introducir un art√≠culo completo como secuencia de entrada y luego generar una secuencia de salida que, en realidad, consistir√° en un par de oraciones que resumen los puntos principales. Los Transformers pueden crear documentos completamente nuevos, por ejemplo, escribir una entrada de blog completa.
>
>Y m√°s all√° del lenguaje, los Transformers han hecho cosas como aprender a jugar ajedrez y realizar un procesamiento de im√°genes que incluso rivaliza con las capacidades de las redes neuronales convolucionales.
>
>Mira, los Transformers son un potente modelo de aprendizaje profundo y, gracias a la capacidad de paralelizar ese mecanismo, est√°n mejorando constantemente.
>¬øY qui√©n sabe?
>Muy pronto, tal vez incluso puedan hacer chistes de pl√°tanos que sean realmente graciosos.

### Quiz 1: Chapter Quiz

>[!NOTE]
>
>![Quiz 1: Chapter Quiz](images/2025-08-06_163419.gif "Quiz 1: Chapter Quiz")


## Section 4: Overview of Machine Learning Model Testing

### 21. Types of Testing in Software

>[!NOTE]
>
>Antes de adentrarnos en la parte esencial de las pruebas de lenguaje, entendamos un poco c√≥mo funcionan las pruebas de software.
>Quiz√°s ya sepas esto.
>Si lo sabes, puedes omitirlo, pero si no, podemos simplemente resumir:
> * **¬øqu√© significa ingenier√≠a de calidad?**
>Generalmente se le llama pruebas de software.
>Por lo tanto, la ingenier√≠a de calidad es el gran √°mbito que se encarga de verificar que se tenga un cierto nivel de calidad en cualquier cosa.
>
> * Una parte de la ingenier√≠a de calidad se denomina pruebas de software.
>Ahora bien, las pruebas de software.
>Tradicionalmente se dividen en
>   * pruebas funcionales y, por supuesto,
>   * pruebas no funcionales.
> * Y si analizamos qu√© son las pruebas funcionales, nos referimos a qu√© hace nuestro producto.
>Qu√© hace.
>Por ejemplo, si queremos ir de A a B, el programa nos dar√° una ruta.
>Y eso es lo que hace.
>Esa es una funcionalidad.
>
>   * Las pruebas no funcionales se refieren al rendimiento de nuestra aplicaci√≥n, sea lo que sea que necesite realizar.</br>
> Algunos ejemplos son las pruebas de rendimiento.
>¬øQu√© tan r√°pido carga nuestra p√°gina web?
>¬øQu√© tan r√°pido genera una imagen nuestro modelo de lenguaje?
>Cuando decimos que generemos una imagen para nosotros.
>   * Las pruebas de seguridad se refieren a que, independientemente de lo que hagamos, est√° protegido y nadie puede acceder a esa informaci√≥n si no se le permite acceder a ella.
>Y hay m√°s.
>
> * La parte funcional, nuevamente, se divide en varias √°reas.
>Pero el objetivo principal es qu√© hace nuestra aplicaci√≥n.
>   * Por ejemplo, las pruebas de aceptaci√≥n del usuario forman parte de las pruebas funcionales.
>   * Luego, se pueden realizar pruebas unitarias, pruebas de integraci√≥n y pruebas de interfaz de usuario.
>Todas se consideran parte de las pruebas funcionales.
>   * Tambi√©n es posible que quieras verificar tus requisitos.
>As√≠ que aseg√∫rate de que tu aplicaci√≥n funcione correctamente.
>S√≠, en comparaci√≥n con tus requisitos.
>
>En resumen, estas son tus pruebas de software.
>Y esto es a gran escala.
>Lo que validas, por supuesto, es que sabes que puedes hablar durante horas sobre qu√© son las pruebas de software.
>Pero para el prop√≥sito de nuestra lecci√≥n, necesitamos entender qu√© es esto.
>
>![Quality Engineering](images/2025-08-12_131314.png "Quality Engineering")



### 22. Understand how ML models are tuned - General View

>[!NOTE]
>
>Ahora solo quiero tomarme un par de minutos para explicar c√≥mo ajustar cualquier tipo de modelo.
>Es muy f√°cil.
>Es como cualquier otro software.
>Como pueden ver, esto es similar al concepto de ramificaci√≥n.
>
>Podr√≠an tener su repositorio de modelos.
>Podr√≠an pensar en esto como la l√≠nea principal, el tronco.
>Y esto podr√≠a ser una rama.
>
>Entonces, lo primero que hacen es modificar su modelo para tener una nueva idea o si su modelo ha sido...
>eh, hay alguna degradaci√≥n, o quieren mejorar su algoritmo o lo que sea.
>
>Entonces, lo que haces es modificar el c√≥digo que cambia tu conjunto de datos y luego ejecutar algunas pruebas preentrenadas.
>Esto significa que aqu√≠ mismo est√°s ejecutando la prueba en un modelo preentrenado.
>Justo en el modelo que est√° aqu√≠.
>
>Despu√©s, vuelves a entrenar el modelo con los datos m√°s recientes, ya que podr√≠as entrenarlo gracias a los datos.
>Podr√≠as tener nuevos datos en el concepto de desviaci√≥n de datos o desviaci√≥n del modelo.
>
>Quieres entrenar con datos nuevos porque los antiguos ya no son relevantes para la situaci√≥n actual, o has cambiado tu algoritmo.
>Tu modelo de aprendizaje autom√°tico se ha modificado con nuevos par√°metros.
>Y por eso, ahora mismo est√°s entrenando tu modelo con tu nuevo algoritmo.
>Y luego ejecutas la nueva prueba.
>
>As√≠ que ahora tienes pruebas que deben validar que el entrenamiento se ajusta a lo que tienes, a lo que quieres hacer con tu modelo m√°s reciente.
>Ese es el punto clave.
>
>Necesitas obtener algunos resultados, pero despu√©s de entrenar, buscas otros resultados que correspondan al nuevo par√°metro.
>Y, por supuesto, esta prueba.
>Tambi√©n se combinan algunas m√©tricas.
>As√≠ que las m√©tricas y los resultados se combinan.
>
>Es como ejecutar una UAT o validar los resultados de la UAT, como podr√≠a ser este.
>Y luego la apruebas y la implementas directamente en producci√≥n.
>Por supuesto, tambi√©n hay una parte donde se podr√≠a hablar de depuraci√≥n de datos.
>As√≠ podr√≠a ser.
>
>Pero suponiendo que tus datos ya est√°n limpios, no necesitas depurar los datos en este punto.
>Correcto.
>Esto significa que te aseguras de que los datos que obtienes sean correctos y no est√©n sesgados.
>Eh, son relevantes, etc.
>
>Al igual que con cualquier tipo de ramificaci√≥n, se modifica la prueba, se ejecuta una prueba previa al entrenamiento, se entrena, se valida el entrenamiento, se revisa, se aprueba y, finalmente, se implementa en producci√≥n.
>Y aqu√≠, por supuesto, se vuelve a supervisar.
>As√≠ es como se ajusta cualquier modelo de aprendizaje autom√°tico.
>
>![Basic Model Tuning](images/2025-08-12_132223.png "Basic Model Tuning")



### 23. Fine tunning techniques for AI and any LLM foundation model

>[!NOTE]
>
>Para comprender completamente la IA, necesitamos detenernos un momento y pensar en el ajuste del modelo.
>Lo que ven aqu√≠ es un ciclo de vida est√°ndar para ajustar un modelo base.
>Porque lo que sucede es que obtendr√°n, por ejemplo, Llama 3, o ChatGPT 01 o cualquier otro modelo de lenguaje extenso.
>Si se trata de un fan√°tico chino, tal vez podr√≠an obtener la versi√≥n 3 profunda, y as√≠ sucesivamente.
>Y aqu√≠ es donde terminan, ¬øverdad?
>
>As√≠ que, de todo el ciclo de vida, preparan sus datos, seleccionan su modelo base y luego eval√∫an el mejor modelo para su tarea.
>Por ejemplo, he visto que Claude Sonnet 3.5 es mejor que ChatGPT 4 en codificaci√≥n.
>As√≠ que quiz√°s seleccione Cloud 3.5 y lo use para codificar.
>Y despu√©s de eso, necesito ajustar mi modelo.
>Esto significa que necesito preparar mi modelo para la tarea espec√≠fica que quiero realizar.
>Porque, no olvidemos que un modelo base como ChatGPT sirve para todo, as√≠ que necesitamos mejorarlo para la tarea en cuesti√≥n.
>
>[![https://mostly.ai/blog/machine-learning-life-cycle-with-synthetic-data](https://mostly-web-mostly-website-assets.s3.eu-central-1.amazonaws.com/wp-content/uploads/2023/08/Machine-learning-life-cycle-1-1-1024x871.jpg "https://mostly.ai/blog/machine-learning-life-cycle-with-synthetic-data")](https://mostly.ai/blog/machine-learning-life-cycle-with-synthetic-data#what-is-a-machine-learning-life-cycle)
>
>Comenzaremos con el conjunto de datos.
>Tienes el conjunto de datos de preentrenamiento y el conjunto de datos de ajuste.
>Lo llamaremos as√≠.
>Selecciona el conjunto de datos completo, que es el 100%, llam√©moslo as√≠.
>Y luego volver√°s a entrenar.
>
>Los modelos ejecutar√°n el algoritmo de entrenamiento con entre el 60% y el 70% de los datos.
>Tu modelo se entrenar√° con estos datos.
>Despu√©s de entrenar tu modelo con estos datos, del 30% o 40% restante, dependiendo de c√≥mo lo dividas,
>necesitamos seleccionar la mitad.
>
>Imaginemos que el 20% se evaluar√° durante el entrenamiento.
>Entrenamos el modelo y luego evaluamos durante el entrenamiento para que la inferencia, que es b√°sicamente la predicci√≥n, se acerque a lo que buscamos.
>Y luego, para el resto, probamos el modelo en un entorno sin entrenamiento, ya que esto es entrenamiento puro.
>Esto es entrenamiento y evaluaci√≥n.
>As√≠ que eval√∫as tus par√°metros para que las inferencias se acerquen a lo deseado.
>Y aqu√≠ esto es evaluaci√≥n pura, sin entrenamiento.
>
>As√≠ que esta es una forma de guiar tu modelo, bas√°ndote en tus datos, para que se acerque m√°s a lo que realmente quieres lograr.
>Esta es una forma de, digamos, evaluar o ajustar tu modelo.
>
>[![.](https://miro.medium.com/v2/resize:fit:1000/1*AE17O-39mBq3PFBalay6-w.png "https://medium.com/data-science/data-splitting-technique-to-fit-any-machine-learning-model-c0d7f3f1c790")](https://medium.com/data-science/data-splitting-technique-to-fit-any-machine-learning-model-c0d7f3f1c790)
>
>La siguiente forma de perfeccionar tu modelo es con indicaciones.
>Si sabes, puedes usar este generador de GPT, que te permite perfeccionar un modelo; de hecho, crear tu propio modelo.
>Lo que hace es, b√°sicamente, perfeccionarlo para una tarea espec√≠fica.
>Tengo la gu√≠a de certificaci√≥n, mi propio modelo de perfeccionamiento, dise√±ado espec√≠ficamente para ayudar a las personas a aprobar la certificaci√≥n.
>Si revisamos la configuraci√≥n, editamos mi GPT, encontrar√°s las instrucciones.
>
>[![https://chatgpt.com/g/g-UpNvtv9X2-istqb-certification-guide](images/2025-08-12_133947.png "https://chatgpt.com/g/g-UpNvtv9X2-istqb-certification-guide")](https://chatgpt.com/g/g-UpNvtv9X2-istqb-certification-guide)
>
>Otra opci√≥n podr√≠a ser usar barandillas.
>AWS ofrece un servicio llamado barandillas.
>Y de lo que quiero hablar espec√≠ficamente es de bloquear temas no deseados.
>Quiz√°s quieras que tu modelo no trate un tema espec√≠fico.
>Quiz√°s est√© prohibido hablar de cualquier tema.
>
>As√≠ que puedes implementar este tipo de barandillas en tu modelo para que solo t√∫ lo sepas.
>Se permite la generaci√≥n de c√≥digo y no se permite nada que est√© fuera de las decisiones o pol√≠ticas de tu empresa.
>Esta es otra forma de ajustar tu modelo de forma granular para restringir la cantidad y los temas que puede gestionar.
>
>Estas son las formas m√°s sencillas de ajustar tu modelo si quieres trabajar con diferentes par√°metros, como el funcionamiento interno de los modelos de aprendizaje autom√°tico, como las redes neuronales.
>
>Luego necesitas profundizar mucho en los modelos de entrenamiento, el aprendizaje autom√°tico y las matem√°ticas.
>Pero, ya sabes, eso es bastante dif√≠cil.
>La forma m√°s f√°cil es recordar los datos.
>Se hace con indicaciones y recopilaciones.
>
>[![https://aws.amazon.com/es/bedrock/guardrails/](images/2025-08-12_135208.png "https://aws.amazon.com/es/bedrock/guardrails/")](https://aws.amazon.com/es/bedrock/guardrails/)
>
>



### 24. Overall Testing Approach to LLMs

>[!NOTE]
>
>Ahora hablemos de nuestro enfoque para probar modelos ling√º√≠sticos grandes.
>El problema es que, en nuestro escenario, o en el caso de los modelos ling√º√≠sticos grandes, es casi imposible probarlo todo, ya que las aplicaciones son pr√°cticamente infinitas.
>
>Por lo tanto, necesitamos un enfoque m√°s estructurado para que, al probar algo, pueda aplicarse en toda la cadena de valor de, digamos, toda la industria.
>Por lo tanto, en nuestro material, al probar modelos ling√º√≠sticos grandes, nos referiremos a tres elementos diferentes.
>
>El primero trata sobre los datos que necesitamos para probar c√≥mo se utilizan en los modelos ling√º√≠sticos grandes.
>
>Necesitamos comprobar que los resultados no contengan datos sesgados.
>Si introduces datos sesgados, quieres asegurarte de que el resultado que obtienes no lo est√©.
>Por lo tanto, los modelos de lenguaje grandes necesitan asegurarse de contar con este tipo de medidas de seguridad.
>
>Al cargar los datos o al proporcionar el resultado, analizaremos datos estad√≠sticamente irrelevantes, ya que, como ya hemos dicho, los modelos de lenguaje grandes son m√°quinas de predicci√≥n estad√≠stica.
>Si las estad√≠sticas no son relevantes, el resultado tampoco lo es.
>Por lo tanto, estas m√°quinas deben tener la capacidad de filtrar este tipo de datos: datos desequilibrados.
>
>Estos datos son estad√≠sticamente relevantes, pero no est√°n, digamos, equilibrados ni a la izquierda ni a la derecha. Veremos qu√© significa esto, o datos obsoletos, porque aprenderemos sobre el concepto de deriva.
>
>Podr√≠as entrenar tu modelo con datos relevantes de hace 15 a√±os, pero que ya no se aplican hoy en d√≠a, y, por supuesto, con otros.
>Luego, haremos pruebas con indicaciones.
>Y cuando digo indicaciones, tambi√©n me refiero a las API.
>
>Cuando llamas a una API para un modelo de lenguaje grande, b√°sicamente la est√°s indicando, pero con un tipo de indicaci√≥n diferente.
>Pero no te preocupes tanto por c√≥mo probar una API.
>Estoy bastante seguro de que puedes encontrar eso en l√≠nea.
>Veremos c√≥mo usar indicaciones para ver si tu modelo de lenguaje grande tiene diferentes capacidades de razonamiento.
>Y, por supuesto, usaremos indicaciones en cascada.
>
>Por ejemplo, indicaciones de cero disparos, indicaciones iterativas, cadena de pensamiento, indicaciones contraf√°cticas, entre otras.
>S√≠, creo que este ser√° el cap√≠tulo m√°s importante que abordaremos.
>
>Y un √∫ltimo punto que analizaremos es la regulaci√≥n de la UE.
>Y, por supuesto, la parte √©tica.
>Aqu√≠ analizaremos las pr√°cticas prohibidas para garantizar que se cuente con las salvaguardas necesarias.
>Transparencia en la toma de decisiones.
>Documentaci√≥n t√©cnica y, por supuesto, mantenimiento de registros.
>Esto tambi√©n est√° regulado.
>Y la capacidad de las personas para supervisar cualquier tipo de interacci√≥n con la IA.
>
>Y el √∫ltimo punto se refiere a los datos y su gobernanza.
>Esto es, ya saben, la parte principal. Habr√° otra parte intermedia sobre seguridad y diferentes tipos de ataques que se pueden realizar para exponer datos o quiz√°s inyectar datos que no se desean.
>Pero hablaremos de eso m√°s adelante.
>
>![Data, Prompts, EU Regulation](images/2025-08-12_140928.png "Data, Prompts, EU Regulation")
>



### 25. Testing Types for LLMs | Foundation Models

>[!NOTE]
>
>As√≠ que, al pensar en pruebas no funcionales para un modelo de lenguaje grande, ya hemos decidido que, de nuevo, se debe tener rendimiento, seguridad, portabilidad, escalabilidad, registro, monitorizaci√≥n y auditor√≠as.
>Cierto.
>Todo esto.
>
>![Quality Engineering"](images/2025-08-12_131314.png "Quality Engineering")
>
>Pero los modelos de lenguaje grandes o la IA tambi√©n necesitan ir m√°s all√° del software tradicional, porque giran en torno a la inteligencia.
>Y recuerden, inteligencia.
>
>Si lo crean humanos, debe imitar el comportamiento humano.
>Por lo tanto, debe pensar como un humano, con sus virtudes y defectos.
>Y por esta raz√≥n, al pensar en probar modelos de lenguaje grandes, y espec√≠ficamente, no funcionales, necesitamos incorporar al menos tres tipos m√°s de pruebas.
>Y en primer lugar, se trata de la √©tica en torno a su modelo de lenguaje grande.
>
> * En primer lugar, se tratar√° la **√©tica** en torno a su modelo ling√º√≠stico general.
>Porque si se utilizan estos modelos, deben incorporar la √©tica humana.
>Y tambi√©n sabemos que, a lo largo de la historia, la √©tica humana no ha evolucionado.
>Quiz√°s no ten√≠amos √©tica en la Edad Media.
>Quiz√°s ten√≠amos algo de √©tica hace unos 100 a√±os y ahora es diferente.
>Por lo tanto, la √©tica debe evaluarse seg√∫n los tiempos modernos, seg√∫n lo que es √©tico en la actualidad.
>Esto es algo que analizaremos en los pr√≥ximos cap√≠tulos.
>
> * Y luego est√° la parte **adversarial**.
>Y cuando digo adversarial, me refiero a un tipo especial de prueba de seguridad que consiste en usar indicaciones para que el modelo act√∫e de forma poco √©tica, para recopilar informaci√≥n del modelo, para extraer informaci√≥n y para enga√±arlo para que haga algo poco √©tico.
>Inyectar indicaciones.
>Envenenar los datos para que el modelo act√∫e de forma poco √©tica o maliciosa, o quiz√°s ense√±arte a fabricar una bomba.
>Por lo tanto, las pruebas adversariales son un tipo de seguridad y tambi√©n las abordaremos en los pr√≥ximos cap√≠tulos.
>
> * Y quiz√°s uno de los aspectos m√°s interesantes es si tu modelo de IA puede actuar como un **humano**.
>Esto significa que cuando hablo con el modelo Doe, ¬øsiente que le estoy hablando?</br>
>En primer lugar, ¬øes un robot o tiene consistencia?
>¬øPierde contexto?
>¬øEs √©tico?
>¬øHabla de la misma manera?
>¬øTiene solidez en la conversaci√≥n?
>
>![Ethics, Adversial, Human](images/2025-08-12_142150.png "Ethics, Adversial, Human")
>
>Estos tambi√©n son algunos aspectos no funcionales del modelo.
>Pero si no los tienes, si el modelo, al hablar con √©l, se siente torpe y est√∫pido,
>y est√°s teniendo una conversaci√≥n sobre algo.
>Y de repente, el modelo responde a una pregunta diferente, y siempre responde de forma diferente,
>y no entiende y te da la misma respuesta una y otra vez.
>
>Es decir, tiene todos los aspectos, quiz√°s no funcionales.
>Puede que tenga la parte funcional, pero no act√∫a como un humano. As√≠ que te vas a frustrar.
>Tambi√©n probaremos este tipo de lado humano, parte de los aspectos no funcionales de un chatbot, o quiz√°s de un modelo de lenguaje m√°s amplio.



### 26. Introduction to Benchmarking for LLMs

>[!NOTE]
>
>En cualquier tipo de industria, digamos.
>Existen ciertos puntos de referencia.
>Existen empresas, o quiz√°s no solo empresas, foros que comparan una cosa con otra para saber cu√°l es mejor.
>
>Por ejemplo, en la industria de los videojuegos, existen CPU o GPU.
>En ciertas aplicaciones o juegos, se comparan en funci√≥n de los fotogramas por segundo que pueden ofrecer.
>Y esto puede aplicarse a cualquier cosa.
>
>Por ejemplo, en la industria automotriz, es la vuelta a N√ºrburgring.
>Entonces, ¬øqu√© tan r√°pido puede un auto dar esa vuelta de 40 km? Y la lista contin√∫a.
>Y, por supuesto, para la IA existen diferentes tipos de puntos de referencia.
>
>Pero entendamos c√≥mo funciona el benchmarking en un modelo de IA.
>Porque normalmente, por ejemplo, si quisiera saber si mi hija sabe contar hasta diez,
>lo har√≠a.
>S√© contar hasta diez.
>Cierto.
>
>Es, digamos, una verdad obvia.
>C√≥mo contar hasta diez en cualquier idioma: uno, dos, tres, etc.
>As√≠ que si quisiera saber si mi hija sabe contar hasta diez, le pedir√≠a que contara hasta diez.
>Y si dijera uno, dos, tres, cuatro, cinco, etc., le dir√≠a que s√≠, pero si dice uno, cuatro, nueve y luego ocho, sabr√≠a que, en comparaci√≥n con el punto de referencia, no est√° rindiendo como deber√≠a.
>
>As√≠ que es b√°sicamente una comparaci√≥n.
>
>Si la comparaci√≥n da igual, sabes que has aprobado.
>Si no, no obtienes puntuaci√≥n y entonces realizas la evaluaci√≥n.
>
>B√°sicamente, comparas los resultados y realizas estas pruebas para quiz√°s 100 preguntas, 100 problemas matem√°ticos diferentes, 100 problemas cient√≠ficos diferentes, problemas universitarios.
>Dependiendo de lo que necesites analizar, existen herramientas de evaluaci√≥n comparativa espec√≠ficas.
>
>![.](images/2025-08-12_143305.png "")
>
>As√≠ es como funciona la evaluaci√≥n comparativa, no solo en IA, sino en cualquier √°mbito.
>Pero en el caso de la IA, necesitas datos de referencia.
>Necesitas un modelo de lenguaje extenso.
>
>Necesitas alg√∫n tipo de herramienta para comparar el resultado dado con el resultado generado por el modelo de lenguaje extenso. Los introduces en un mecanismo de puntuaci√≥n, luego emites una puntuaci√≥n y listo.
>Puedes comparar diferentes modelos de lenguaje extensos entre s√≠ dentro del mismo conjunto de datos.
>

